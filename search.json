[{"title":"REST架构简析（原论文整理）","url":"/2018/07/20/REST架构简析（原论文整理）/","content":"# 0 引言\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目前，互联网在社会中扮演的角色越来越重要。通过互联网为广大群众提供服务，也是互联网成功的关键。互联网服务架构目前大多数都是基于REST架构来完成的。REST从它诞生至今，可以说为互联网的繁荣做出了不可磨灭的贡献。REST架构到底是一种什么样的架构，而它为何有这种魔力，这里我们就来刨根问底，挖掘它的内在以及潜在意义。\n# 1 绪论\n## 1.1 软件架构\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;软件架构是一种软件运行时的抽象。软件运行的健壮性、扩展性、效率，软件使用的简洁性通常用来评判一种软件好坏的标志，也是一个软件架构优劣的标志。 \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;软件架构包含以下要素：组件、连接器和数据。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;软件架构设计的目标是创建具有一组架构属性的架构，这些架构构成了系统需求的超集。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;构建派生树为架构设计提供了一种指导机制。\n## 1.2 基于网络的软件架构\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于网络的软件架构，顾名思义，它是网络条件下提供服务的软件的架构。 \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关键利益的架构属性包括：表现（网络性能、用户感知的性能、网络效率）、可扩展性、简单、可修改性（进化性、可扩展性、可定制性、可配置性、可重用性）、可见性、便携性、可靠性  \n## 1.3 基于网络的软件架构样式\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;软件架构样式的分类是基于这些样式引起的架构特性来决定的。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于网络的软件架构样式包括：数据流样式、复制样式、分层样式、移动代码样式、点对点样式。\n\n## 1.3.1 复制样式\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于复制样式的系统通过让多个进程提供相同的服务来提高数据的可访问性和服务的可伸缩性。这些分散的服务器相互作用，为客户提供只有一个服务的错觉。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**示例：** 分布式文件系统和远程版本控制系统。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**优势：**  改善用户感知性能、简单性保持中立（因为复制的复杂性被允许网络无意识组件在本地复制数据上的透明操作）。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**缓存：** 缓存可以说是复制存储的变体  \n\n## 1.3.2 分层样式\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;客户端 - 服务器样式是基于网络的应用程序的架构样式中最常遇到的。提供一组服务的服务器组件侦听对这些服务的请求。希望执行服务的客户端组件通过连接器向服务器发送请求。服务器拒绝或执行请求并将响应发送回客户端。 \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;客户端 - 服务器组件如下：客户端是一个触发过程; 服务器是一个被动的过程。客户端发出触发服务器响应的请求。因此，客户在其选择时启动活动; 它通常会延迟，直到其请求得到服务。另一方面，服务器等待发出请求然后对它们作出反应。服务器通常是非终止进程，通常为多个客户端提供服务。  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;客户端-服务器约束背后的主要原则的关注点分离。正确分离功能应简化服务器组件，以提高可伸缩性。这种简化通常采用将所有用户界面功能移动到客户端组件中的形式。分离还允许两种类型的组件独立发展，前提是接口不会改变。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;客户端 - 服务器的基本形式不限制应用程序状态在客户端和服务器组件之间的分区方式。它通常由用于连接器实现的机制引用，例如远程过程调用或面向消息的中间件。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分层系统按层次结构组织，每个层为其上方的层提供服务，并使用其下层的服务。虽然分层系统被认为是“纯粹”的风格，但它在基于网络的系统中的使用仅限于它与客户端 - 服务器风格的结合，以提供分层客户端服务器。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分层系统通过将内层隐藏在除相邻外层之外的所有层来减少跨多层的耦合，从而改善了可演化性和可重用性。示例包括分层通信协议的处理，例如TCP / IP和OSI协议栈，以及硬件接口库。分层系统的主要缺点是它们增加了数据处理的开销和延迟，降低了用户感知的性能。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分层客户端服务器将代理和网关组件添加到客户端 - 服务器样式。代理充当一个或多个客户端组件的共享服务器，接收请求并将它们以可能的转换转发到服务器组件。网关组件似乎是请求其服务的客户端或代理的普通服务器，但实际上是将这些请求（可能的转换）转发到其“内层”服务器。可以在多个层中添加这些其他介体组件，以向系统添加负载平衡和安全检查等功能。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于分层客户端服务器的体系结构在信息系统文献中被称为双层，三层或多层体系结构。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**示例：** 远程会话、远程数据库访问。\n## 1.3.3 移动代码样式\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;移动代码样式使用移动性来动态地改变处理和数据源或结果目的地之间的距离。作为活动配置的一部分，在体系结构级别引入了站点抽象，以便考虑不同组件的位置。引入位置概念使得在设计级别对组件之间的交互成本进行建模成为可能。特别地，与涉及通过网络的通信的交互相比，共享相同位置的组件之间的交互被认为具有可忽略的成本。通过改变其位置，组件可以改善其交互的接近度和质量，降低交互成本，从而提高效率和用户感知的性能。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在所有移动代码样式中，数据元素被动态转换为组件。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所有移动代码样式的基础是虚拟机或解释器风格的概念。代码必须以某种方式执行，最好是在受控环境中，以满足安全性和可靠性问题，这正是虚拟机风格所提供的。它本身不是基于网络的样式，但当与客户端 - 服务器样式（REV和COD样式）中的组件结合使用时，它通常会被用作这种样式。  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**示例：** \n\n- 远程评估：客户端组件具有执行服务所需的专有技术，但缺少所需的资源（CPU周期，数据源等），恰好位于远程站点。因此，客户端将技术诀窍发送到远程站点的服务器组件，该服务器组件又使用那里可用的资源来执行代码。然后将执行结果发送回客户端。远程评估样式假定所提供的代码将在受保护的环境中执行，这样除了正在使用的资源之外，它不会影响同一服务器的其他客户端。\n- 按需代码：在按需代码样式中，客户端组件可以访问一组资源，但不能访问如何处理它们的专有技术。它向远程服务器发送请求，以获取代表该技术诀窍的代码，接收该代码并在本地执行该代码。\n- 移动代理：在移动代理风格中，整个计算组件与其状态，所需代码以及执行任务所需的一些数据一起被移动到远程站点。这可以被认为是远程评估和按需编码样式的推导，因为移动性可以双向工作。 \n \n# 2 设计Web架构：问题和见解\n## 2.1 万维网应用程序要求\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;伯纳斯 - 李写道，“网络的主要目标是成为人和机器可以通信的共享信息空间。” 所需要的是人们存储和构建他们自己的信息的方式，无论是永久性的还是短暂的，以便它本身和其他人可以使用，并且能够参考和构建他人存储的信息，以便它没有必要让每个人保持和维护本地副本。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该系统的预期最终用户位于世界各地，通过互联网连接的各种大学和政府高能物理研究实验室。他们的机器是终端，工作站，服务器和超级计算机的异构集合，需要大量的操作系统软件和文件格式。信息范围从个人研究笔记到组织电话列表。面临的挑战是建立一个系统，为这种结构化信息提供通用的一致界面，尽可能在尽可能多的平台上提供，并在新人和组织加入项目时逐步部署。\n### 2.1.1 低入口障碍\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于参与信息的创建和构建是自愿的，因此需要较低的准入门槛以实现充分的采用。这适用于Web体系结构的所有用户：读者，作者和应用程序开发人员。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;超媒体被选为用户界面，因为它简单和通用：无论信息源如何，都可以使用相同的界面，超媒体关系（链接）的灵活性允许无限制的结构，直接操纵链接允许内部的复杂关系指导读者完成申请的信息。由于大型数据库中的信息通常更容易通过搜索界面而不是浏览来访问，因此Web还通过向服务提供用户输入的数据并将结果呈现为超媒体来结合执行简单查询的能力。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于作者来说，主要要求是整个系统的部分可用性不得妨碍内容的创作。超文本创作语言必须简单并且能够使用现有编辑工具创建。作者需要保留这种格式的个人研究笔记，无论是否直接连接到互联网，因此暂时或永久地提供某些参考信息的事实不能阻止阅读和创作。可用的信息。出于类似的原因，必须能够在该参考的目标可用之前创建对信息的引用。由于鼓励作者在信息源的开发方面进行合作，因此参考文献需要易于沟通。 \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;简单性也是应用程序开发人员的目标。由于所有协议都被定义为文本，因此可以使用现有网络工具查看和交互测试通信。尽管缺乏标准，这使得早期采用协议成为可能。  \n### 2.1.2 可扩展性\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然简单性可以部署分布式系统的初始实现，但可扩展性使我们能够避免因部署的限制而永远陷入困境。即使可以构建完全符合其用户要求的软件系统，这些要求也会随着社会随着时间的推移而变化。一个打算像Web一样长寿的系统必须为变革做好准备。  \n### 2.1.3 分布式超媒体\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;超媒体的定义是信息呈现中嵌入的应用程序控制信息的存在或上面的层。分布式超媒体允许将演示和控制信息存储在远程位置。就其本质而言，分布式超媒体系统内的用户动作需要将大量数据从存储数据的位置传输到使用它的位置。因此，Web架构必须设计用于大粒度数据传输。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;超媒体交互的可用性对用户感知的延迟高度敏感：选择链接和呈现可用结果之间的时间。由于Web的信息源分布在全球Internet上，因此架构需要最小化网络交互（数据传输协议内的往返）。  \n### 2.1.4 互联网规模\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Web旨在成为一个互联网规模的分布式超媒体系统，这意味着不仅仅是地理分散。互联网是指跨多个组织边界互连信息网络。信息服务的供应商必须能够应对无政府可扩展性和软件组件的独立部署的需求。  \n#### 2.1.4.1 无状态可扩展性  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大多数软件系统是在隐含的假设下创建的，即整个系统处于一个实体的控制之下，或者至少参与系统内的所有实体都在朝着共同目标而不是交叉目的行事。当系统在因特网上公开运行时，不能安全地做出这样的假设。无状态可扩展性是指架构元素在遭受意外负载时或在给出格式错误或恶意构造的数据时需要继续运行，因为它们可能与组织控制之外的元素进行通信。该体系结构必须适合增强可见性和可伸缩性的机制。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;无状态性可扩展性要求适用于所有架构元素。不能期望客户端保持所有服务器的状态。不能期望服务器跨请求保留状态知识。超媒体数据元素不能保留“反向指针”，即引用它们的每个数据元素的标识符，因为对资源的引用数量与对该信息感兴趣的人数成比例。特别值得注意的信息也可能导致“闪电人群”：随着其可用性的消息传播到全世界，访问尝试突然激增。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;建筑元素的安全性以及它们运行的平台也成为一个重要的问题。多个组织边界意味着在任何通信中都可能存在多个信任边界。中间件应用程序（例如防火墙）应该能够检查应用程序交互并防止对组织安全策略之外的人员采取行动。应用程序交互的参与者应该假定所接收的任何信息都是不可信的，或者在获得信任之前需要一些额外的身份验证。这要求体系结构能够传递身份验证数据和授权控制。  \n#### 2.1.4.2 独立部署\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;多个组织边界还意味着系统必须为逐步和零散的变更做好准备，新旧实现共存，而不会阻止新实现利用其扩展功能。需要设计现有的架构元素，期望将添加以后的架构特征。同样，需要轻松识别较旧的实现，以便可以封装遗留行为，而不会对新的体系结构元素产生负面影响。整个体系结构必须设计为以部分，迭代的方式简化体系结构元素的部署，因为不可能以有序的方式强制部署。  \n\n## 2.2 问题\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在1993年末，很明显，不仅仅是研究人员会对网络感兴趣。网络首先发生在小型研究小组中，然后传播到校园宿舍，俱乐部和个人主页，然后传播到机构部门获取校园信息。当个人开始发布他们的个人信息集时，无论他们可能感到什么狂热的话题，社交网络效应推动了今天持续的网站的指数增长。对网络的商业兴趣才刚刚开始，但很明显，在国际范围内发布的能力对企业来说是不可抗拒的。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;尽管互联网开发者社区的成功令人高兴，但他们开始担心网络使用的快速增长以及早期HTTP的一些不良网络特征将迅速超过互联网基础设施的容量并导致全面崩溃。由于Web上应用程序交互的性质不断变化，这种情况更加恶化。尽管初始协议是针对单个请求 - 响应对而设计的，但新站点使用越来越多的内嵌图像作为网页内容的一部分，从而产生用于浏览的不同交互配置文件。部署的体系结构在支持可扩展性，共享缓存和中介体方面存在很大的局限性，这使得难以针对不断增长的问题开发临时解决方案。与此同时，\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Internet工程任务组内的工作组成立于Web的三个主要标准：URI，HTTP和HTML。这些组的章程是定义现有架构通信的子集，这些子集在早期Web架构中通常一致地实现，识别该架构中的问题，然后指定一组标准来解决这些问题。这给我们带来了一个挑战：我们如何为已经广泛部署的体系结构引入一组新功能，以及我们如何确保其引入不会对启用Web的体系结构属性产生负面影响甚至破坏成功？\n\n## 2.3 方法\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;早期的Web架构基于可靠的原则 - 关注点分离，简单性和通用性 - 但缺乏架构描述和基本原理。该设计是基于一套非正式的超文本笔，对用户社区和Web开发者社区邮件列表存档的讨论（www-talk@info.cern.ch） 。然而，实际上，早期Web架构的唯一真实描述是在libwww（客户端和服务器的CERN协议库），Mosaic（NCSA浏览器客户端）以及与它们互操作的各种其他实现的实现中找到的。 。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;架构风格可用于定义Web架构背后的原则，以便未来的架构师可以看到它们。如第1章所述，样式是体系结构元素上的一组命名约束，它引入了体系结构所需的属性集。因此，我的方法的第一步是确定早期Web架构中对其所需属性负责的约束。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设I：WWW体系结构背后的设计原理可以通过一种体系结构样式来描述，该体系结构样式由应用于Web体系结构中的元素的约束集组成。\n可以将附加约束应用于体系结构样式，以便扩展在实例化体系结构上引发的属性集。我的方法的下一步是确定互联网规模的分布式超媒体系统中所需的属性，选择诱导这些属性的其他架构风格，并将它们与早期的Web约束相结合，以形成现代Web的新的混合架构风格。建筑。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设II：可以将约束添加到WWW体系结构样式中，以获得更好地反映现代Web体系结构所需属性的新混合样式。\n使用新的体系结构样式作为指导，我们可以将建议的扩展和对Web体系结构的修改与样式中的约束进行比较。冲突表明该提案违反了Web背后的一个或多个设计原则。在某些情况下，可以通过在使用新功能时要求使用特定指示符来消除冲突，这通常对影响响应的默认可缓存性的HTTP扩展进行。对于严重的冲突，例如交互风格的改变，相同的功能要么被更有利于Web风格的设计所取代，要么被告知提议者将功能实现为与Web并行运行的独立体系结构。 。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设III：可以将修改Web体系结构的提议与更新的WWW体系结构样式进行比较，并在部署之前分析冲突。\n最后，通过参与构成大多数Web应用程序的基础架构和中间件软件的开发，部署了根据新架构风格指南编写的修订协议标准所定义的更新Web架构。这包括我直接参与Apache HTTP服务器项目和libwww-perl客户端库的软件开发，以及通过为W3C libwww和jigsaw项目，Netscape Navigator，Lynx和MSIE的开发人员提供建议，间接参与其他项目。浏览器和许多其他实现，作为IETF话语的一部分。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然我已将此方法描述为单个序列，但实际上它是以非顺序，迭代的方式应用的。也就是说，在过去六年中，我一直在构建模型，为架构风格添加约束，并通过客户端和服务器软件的实验扩展来测试它们对Web协议标准的影响。同样，其他人建议在架构中添加超出当前模型样式范围的功能，但不与其冲突，这导致返回并修改架构约束以更好地反映改进的架构。我们的目标始终是保持一致且正确的模型，即我打算如何构建Web体系结构，以便它可以用于指导定义适当行为的协议标准。\n\n# 3 REST架构风格\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST是一种混合风格，它源自第1章中描述的几种基于网络的体系结构样式，并结合了定义统一连接器接口的其他约束。第1章的软件体系结构框架用于定义REST的体系结构元素，并检查原型体系结构的样本过程，连接器和数据视图。\n## 3.1 派生REST\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Web体系结构背后的设计原理可以通过体系结构样式来描述,该体系结构样式由应用于体系结构中的元素的约束集组成。通过检查每个约束在添加到演化样式时的影响，我们可以识别由Web约束引起的属性.然后可以应用其他约束来形成新的体系结构样式，以更好地反映现代Web体系结构的所需属性。本节通过介绍将其作为架构风格派生的过程，提供REST的一般概述。后面的部分将更详细地描述组成REST样式的特定约束。 \n### 3.1.1 从空样式开始\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;建筑设计过程有两个共同的观点，无论是建筑物还是软件。第一个是设计师从零开始 - 空白的板岩，白板或绘图板 - 并从熟悉的组件构建架构，直到满足预期系统的需求。第二个是设计师从系统需求开始，没有约束，然后逐步识别并应用系统元素的约束，以区分设计空间，并允许影响系统行为的力自然流动，与系统和谐相处。第一个强调创造力和无限视觉，第二个强调对系统环境的约束和理解。使用后一种方法开发了REST。  \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;空样式只是一组空的约束。从体系结构的角度看，空样式描述了一个系统其中组件之间没有明显的边界这是我们描述REST的起点。\n\n### 3.1.2 客户端-服务器\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;添加到混合样式的第一个约束是客户端 - 服务器体系结构样式。关注点分离是客户端 - 服务器约束背后的原则。通过将用户界面问题与数据存储问题分开，我们提高了跨多个平台的用户界面的可移植性，并通过简化服务器组件来提高可伸缩性。然而，对Web而言最重要的是，分离允许组件独立发展，从而支持多个组织域的Internet规模需求。\n\n### 3.1.3 无状态\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;接下来我们为客户端 - 服务器交互添加一个约束：通信本质上必须是无状态的。这样每个请求从客户端到服务器必须包含理解请求所需的所有信息，并且不能利用服务器上任何存储的上下文。因此，会话状态完全保留在客户端上。此约束会引发可见性，可靠性和可伸缩性。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可见性得到改善，因为监控系统不必超出单个请求数据，以确定请求的完整性。可靠性得到改善，因为它简化了从部分故障中恢复的任务。扩展性得到改善，因为不必在请求之间存储状态允许服务器组件快速释放资源，并进一步简化实现，因为服务器不必跨请求管理资源使用。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与大多数架构选择一样，无状态约束反映了设计权衡。缺点是它可能通过增加在一系列请求中发送的重复数据（每个交互开销）来降低网络性能，因为该数据不能在共享上下文中留在服务器上。此外，将应用程序状态放在客户端会降低服务器对一致应用程序行为的控制，因为应用程序依赖于跨多个客户端版本的语义的正确实现。\n\n### 3.1.4 缓存\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了提高网络效率，我们添加了缓存约束以形成客户端缓存无状态服务器样式。高速缓存约束要求将对请求的响应中的数据隐式或显式标记为可高速缓存或不可高速缓存。如果响应是可缓存的，则客户端缓存有权重用该响应数据以用于以后的等效请求。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;添加缓存约束的优势在于，它们有可能通过减少一系列交互的平均延迟来部分或完全消除某些交互，从而提高效率，可伸缩性和用户感知性能。然而，权衡的是，如果高速缓存中的陈旧数据与请求被直接发送到服务器时获得的数据显著不同，则高速缓存会降低可靠性。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;早期的Web架构是由客户端缓存无状态服务器约束集定义的。也就是说，1994年之前为Web架构提供的设计原理侧重于通过Internet交换静态文档的无状态客户端 - 服务器交互。用于通信交互的协议对非共享缓存具有基本支持，但并未将接口限制为所有资源的一致语义集。相反，Web依赖于使用通用客户端 - 服务器实现库（CERN libwww）来维护Web应用程序之间的一致性。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目前，Web开发已经超出了早期的设计。除静态文档外，请求还可以识别动态生成响应的服务，例如图像映射[Kevin Hughes]和服务器端脚本[Rob McCool]。代理和共享缓存 形式的中间组件也已开始工作，但需要对协议进行扩展才能使它们可靠地进行通信。以下部分描述了添加到Web体系结构样式的约束，以指导构成现代Web体系结构的扩展。\n\n### 3.1.5 统一接口\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将REST架构样式与其他基于网络的样式区分开来的核心功能是强调组件之间的统一接口。通过将通用性的软件工程原理应用于组件接口，简化了整个系统架构，提高了交互的可见性。实现与它们提供的服务分离，这鼓励了独立的可进化性。然而，权衡的是，统一的接口会降低效率，因为信息是以标准化的形式传输的，而不是特定于应用程序需求的形式。REST接口旨在高效地进行大粒度超媒体数据传输，并针对Web的常见情况进行优化，然而，它又会带来界面不适合其他形式的架构交互的负面效应。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了获得统一的接口，需要多个架构约束来指导组件的行为。REST由四个接口约束定义：资源识别、 通过陈述来处理资源、 自我描述性的信息和超媒体作为应用程序状态的引擎。\n\n### 3.1.6 分层系统\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了进一步改善Internet规模要求的行为，我们添加了分层系统约束。分层系统样式允许通过约束组件行为来使架构由分层组成，使得每个组件不能“看到”超出与它们交互的直接层。通过将系统知识限制在单一层，我们限制了整个系统的复杂性并促进了基板的独立性。层可用于封装旧服务并保护旧服务的新服务，通过将不常用的功能移动到共享中介来简化组件。通过在多个网络和处理器之间实现服务的负载平衡，中介还可用于提高系统可扩展性。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分层系统的主要缺点是它们增加了数据处理的开销和延迟，降低了用户感知的性能。对于支持缓存约束的基于网络的系统，这可以通过中间人的共享缓存的好处来抵消。将共享缓存放置在组织域的边界可以带来显着的性能优势。这些层还允许对跨越组织边界的数据实施安全策略，这是防火墙所要求的。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分层系统和均匀界面约束的组合引起类似于均匀管道和过滤器类型的建筑特性。虽然REST交互是双向的，但是超媒体交互的大粒度数据流可以像数据流网络一样被处理，其中过滤器组件选择性地应用于数据流，以便在内容通过时转换内容。在REST中，中间组件可以主动转换消息内容，因为消息是自描述的，并且它们的语义对于中介是可见的。\n\n### 3.1.7 按需代码\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST的约束集的最终添加来自第1.3.3节的移动代码样式。REST允许通过以applet或脚本的形式下载和执行代码来扩展客户端功能。这通过减少预先实现所需的功能数量来简化客户端。允许在部署后下载功能可以提高系统的可扩展性。但是，它还会降低可见性，因此只是REST中的可选约束。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可选约束的概念可能看起来像矛盾。但是，它在包含多个组织边界的系统的体系结构设计中确实有用。这意味着当已知对于整个系统的某些领域有效时，该体系结构仅获得可选约束的益处（并且具有缺点）。例如，如果已知组织内的所有客户端软件都支持Java applet，然后，可以构建该组织内的服务，以便通过可下载的Java类获得增强功能的好处。但是，同时，组织的防火墙可能会阻止Java小程序从外部源传输，因此对于Web的其余部分，它看起来好像这些客户端不支持按需代码。可选约束允许我们设计一种在一般情况下支持所需行为的体系结构，但要了解它可能在某些上下文中被禁用。\n\n\n## 3.2 REST架构元素\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Representational State Transfer（REST）样式是分布式超媒体系统中的架构元素的抽象。REST忽略了组件实现和协议语法的细节，以便专注于组件的角色，与其他组件交互的约束以及对重要数据元素的解释。它包含对组件，连接器和数据的基本约束，这些约束定义了Web体系结构的基础，因此也就是其作为基于网络的应用程序的行为的本质。\n\n### 3.2.1 数据元素\n\n数据元素 | 现代web示例\n---|---\n资源 | 超文本引用的预期概念目标\n资源标识符 | URL，URN\n表示 | HTML文档，JPEG图像\n表示元数据 | 媒体类型，最后修改时间\n资源元数据 | 源链接，交替，变化\n控制数据 | if-modified-since，cache-control\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST通过关注数据类型与元数据的共享理解，提供了所有三个选项的混合，但限制了标准化界面的显示范围。REST组件通过以匹配一组演进的标准数据类型之一的格式传送资源的表示来进行通信，所述标准数据类型基于接收者的能力或期望以及资源的性质而动态地选择。表示是否与原始源具有相同的格式，或者是否源自源，仍然隐藏在接口后面。通过发送由封装渲染引擎的标准数据格式中的指令组成的表示来近似移动对象样式的好处。因此，REST可以在没有服务器可伸缩性问题的情况下实现客户端 - 服务器风格的关注分离，允许通过通用接口隐藏信息以实现服务的封装和演进，并通过可下载的功能引擎提供各种功能。\n\n#### 3.2.1.1 资源和资源标识符\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST中信息的关键抽象是一种资源。可以命名的任何信息都可以是资源：文档或图像，临时服务（例如“洛杉矶的今天天气”），其他资源的集合，非虚拟对象（例如人）等等。换句话说，任何可能是作者超文本引用目标的概念都必须符合资源的定义。资源是到一组实体的概念映射，而不是与任何特定时间点的映射相对应的实体。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;更确切地说，资源R是时间上变化的隶属函数M R（t），其对于时间t映射到一组实体或等价的值。集合中的值可以是资源表示和/或资源标识符。资源可以映射到空集，允许在任何实现该概念之前对概念进行引用 - 这一概念对于Web之前的大多数超文本系统来说是陌生的[ 61]]。某些资源在某种意义上是静态的，当它们在创建后的任何时间进行检查时，它们总是对应于相同的值集。其他人的价值随时间变化很大。对于资源而言，唯一需要静态的是映射的语义，因为语义是区分一个资源与另一个资源的区别。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如，学术论文的“作者'首选版本”是其值随时间变化的映射，而映射到“在会议X的会议论文中发表的论文”是静态的。这是两个不同的资源，即使它们在某个时间点都映射到相同的值。区分是必要的，以便可以独立地识别和引用这两种资源。软件工程中的类似示例是在引用“最新版本”，“版本号1.2.7”或“橙色版本附带的修订版”时单独标识版本控制的源代码文件。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种资源的抽象定义实现了Web体系结构的关键功能。首先，它通过包含许多信息来源提供了一般性，而没有按类型或实施人为地区分它们。其次，它允许将引用后期绑定到表示，从而允许基于请求的特征进行内容协商。最后，它允许作者引用该概念而不是该概念的某些单一表示，从而无需在表示发生变化时更改所有现有链接（假设作者使用了正确的标识符）。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST使用资源标识符来标识组件之间交互中涉及的特定资源。无论如何定义成员函数或处理请求的软件类型，REST连接器都提供用于访问和操作资源值集的通用接口。分配资源标识符使得可以引用资源的命名机构负责维持映射随时间的语义有效性（即，确保成员函数不改变）。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;传统的超文本系统通常在封闭或本地环境中运行，使用每次信息更改时都会发生变化的唯一节点或文档标识符，依靠链接服务器来维护与内容分开的引用。由于集中式链接服务器是对Web的巨大规模和多组织域要求的诅咒，因此REST依赖于作者选择最符合所识别概念性质的资源标识符。当然，标识符的质量通常与保留其有效性所花费的金额成比例，这导致链接断开，因为短暂（或支持不良）的信息随着时间的推移而移动或消失。\n\n#### 3.2.1.2 表示\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST组件通过使用表示来捕获资源的当前或预期状态并在组件之间传输该表示，从而对资源执行操作。表示是字节序列，加上用于描述这些字节的表示元数据。其他常用但不太精确的表示名称包括：文档，文件和HTTP消息实体，实例或变体。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;表示由数据，描述数据的元数据以及有时描述元数据的元数据（通常用于验证消息完整性）组成。元数据采用名称 - 值对的形式，其中名称对应于定义值的结构和语义的标准。响应消息可以包括表示元数据和资源元数据：关于不是特定于所提供的表示的资源的信息。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;控制数据定义组件之间消息的目的，例如所请求的操作或响应的含义。它还用于参数化请求并覆盖某些连接元素的默认行为。例如，可以通过请求或响应消息中包括的控制数据来修改高速缓存行为。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据消息控制数据，给定表示可以指示所请求资源的当前状态，所请求资源的期望状态，或某些其他资源的值，例如客户端查询形式内的输入数据的表示，或者表示响应的某些错误条件。例如，资源的远程创作要求作者向服务器发送表示，从而为该资源建立可由后来的请求检索的值。如果给定时间的资源的值集由多个表示组成，则可以使用内容协商来选择包含在给定消息中的最佳表示。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;表示的数据格式称为媒体类型。表示可以包括在消息中并由接收者根据消息的控制数据和媒体类型的性质进行处理。一些媒体类型旨在用于自动处理，一些媒体类型旨在被呈现以供用户查看，并且一些媒体类型能够用于两者。复合媒体类型可用于在单个消息中包含多个表示。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;媒体类型的设计可以直接影响分布式超媒体系统的用户感知性能。在收件人开始呈现表示之前必须接收的任何数据都会增加交互的延迟。一种数据格式，可以预先放置最重要的渲染信息，这样可以在接收其余信息时逐步渲染初始信息，从而产生比以前必须完全接收的数据格式更好的用户感知性能渲染可以开始。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如，即使网络性能相同，可以在接收大量HTML文档时逐步呈现大型HTML文档的Web浏览器提供的用户感知性能明显优于在呈现之前等待整个文档完全接收的文档。请注意，表示的呈现能力也可能受到内容选择的影响。如果必须在渲染动态大小的表和嵌入对象之前确定它们的尺寸，则它们在超媒体页面的查看区域内的出现将增加其延迟。\n\n### 3.2.2 连接器\n\n\n连接器 | 现代web示例\n---|---\n客户 | libwww，libwww-perl\n服务器 | libwww，Apache API，NSAPI\n高速缓存 | 浏览器缓存，Akamai缓存网络\n分解器 | 绑定（DNS查找库）\n隧道 | HTTP CONNECT后的SOCKS，SSL\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST使用上表中汇总的各种连接器类型来封装访问资源和传输资源表示的活动。连接器为组件通信提供了一个抽象接口，通过提供关注点的清晰分离和隐藏资源和通信机制的底层实现来增强简单性。接口的通用性还具有可替代性：如果用户只能通过抽象接口访问系统，则可以在不影响用户的情况下替换实现。由于连接器管理组件的网络通信，因此可以跨多个交互共享信息，以提高效率和响应性。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所有REST交互都是无状态的。也就是说，每个请求都包含连接器理解请求所需的所有信息，与之前可能存在的任何请求无关。此限制实现了四个功能：1）它消除了连接器在请求之间保留应用程序状态的任何需要，从而减少了物理资源的消耗并提高了可伸缩性; 2）它允许并行处理交互，而不需要处理机制理解交互语义; 3）它允许中介单独查看和理解请求，这在动态重新安排服务时可能是必要的; 4）它强制所有可能影响缓存响应的可重用性的信息出现在每个请求中。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;连接器接口类似于过程调用，但在参数和结果的传递方面存在重要差异。参数包括请求控制数据，指示请求目标的资源标识符和可选表示。out参数包括响应控制数据，可选资源元数据和可选表示。从抽象的角度来看，调用是同步的，但in-out和out-parameters都可以作为数据流传递。换句话说，可以在完全知道参数的值之前调用处理，从而避免批量处理大数据传输的等待时间。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;主连接器类型是客户端和服务器。两者之间的本质区别在于客户端通过发出请求来启动通信，而服务器侦听连接并响应请求以提供对其服务的访问。组件可以包括客户端和服务器连接器。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第三种连接器类型（缓存连接器）可以位于客户端或服务器连接器的接口上，以便保存对当前交互的可缓存响应，以便可以将它们重用于以后请求的交互。客户端可以使用高速缓存来避免重复网络通信，或者服务器可以使用高速缓存来避免重复生成响应的过程，两种情况都用于减少交互等待时间。缓存通常在使用它的连接器的地址空间内实现。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;某些缓存连接器是共享的，这意味着其缓存的响应可用于回答除最初获得响应的客户端之外的客户端。共享缓存可以有效地减少“闪存拥挤”对流行服务器负载的影响，特别是当分层安排缓存以覆盖大型用户组时，例如公司内部网中的用户，Internet服务的客户提供者或共享国家网络骨干的大学。但是，如果缓存的响应与新请求所获得的响应不匹配，则共享缓存也会导致错误。REST尝试平衡缓存行为透明度的愿望与有效使用网络的愿望，而不是假设始终需要绝对透明度。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;缓存能够确定响应的可缓存性，因为该接口是通用的，而不是特定于每个资源。默认情况下，对检索请求的响应是可缓存的，对其他请求的响应是不可缓存的。如果某种形式的用户身份验证是请求的一部分，或者响应指示不应该共享，则响应只能由非共享缓存缓存。组件可以通过包含控制数据来覆盖这些默认值，该控制数据仅在有限时间内将交互标记为可缓存，不可缓存或可缓存。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;解析器将部分或完整资源标识符转换为建立组件间连接所需的网络地址信息。例如，大多数URI包括DNS主机名作为用于标识资源的命名权限的机制。为了发起请求，Web浏览器将从URI中提取主机名，并使用DNS解析器获取该权限的Internet协议地址。另一个示例是一些识别方案（例如，URN需要中间设备将永久标识符转换为更临时的地址以便访问所识别的资源。使用一个或多个中间解析器可以通过间接提高资源引用的寿命，但这样做会增加请求延迟。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;连接器类型的最终形式是隧道，它简单地中继通过连接边界的通信，例如防火墙或低级网络网关。将其建模为REST的一部分并且不作为网络基础结构的一部分进行抽象的唯一原因是某些REST组件可以动态地从活动组件行为切换到隧道的行为。主要示例是HTTP代理，它响应CONNECT方法请求切换到隧道，从而允许其客户端使用不允许代理的不同协议（如TLS）直接与远程服务器通信。当两端终止通信时，隧道消失。\n\n### 3.2.3 组件\n\n\n组件 | 现代web示例\n---|---\n原始服务器 | Apache httpd，Microsoft IIS\n网关 | Squid，CGI，反向代理\n代理 | CERN代理，Netscape代理，Gauntlet\n用户代理 | Netscape Navigator，Lynx，MOMspider\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用户代理使用客户端连接器来发起请求，并成为响应的最终接收者。最常见的示例是Web浏览器，它提供对信息服务的访问并根据应用程序需求呈现服务响应。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;源服务器使用服务器连接器来管理所请求资源的命名空间。它是表示其资源的权威来源，并且必须是任何打算修改其资源价值的请求的最终接收者。每个源服务器都将其服务的通用接口作为资源层次结构提供。资源实现细节隐藏在界面后面。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;中介组件既作为客户又作为服务器，以便转发可能的翻译，请求和响应。代理组件是客户端选择的中介，用于提供其他服务的接口封装，数据转换，性能增强或安全保护。网关（也称为反向代理）组件是由网络或源服务器强加的中介，以提供其他服务的接口封装，用于数据转换，性能增强或安全实施。请注意，代理和网关之间的区别在于客户端确定何时使用代理。\n\n## 3.3 REST架构视图\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在我们已经单独了解了REST架构元素，我们可以使用架构视图来描述元素如何协同工作以形成架构。三种类型的视图 - 进程，连接器和数据 - 对于阐明REST的设计原则非常有用。\n\n### 3.3.1 流程视图\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST的客户端 - 服务器关注点分离简化了组件实现，降低了连接器语义的复杂性，提高了性能调优的效率，并提高了纯服务器组件的可伸缩性。分层系统约束允许在通信中的各个点处引入中介 - 代理，网关和防火墙 - 而不改变组件之间的接口，从而允许它们通过大规模共享缓存来协助通信转换或提高性能。REST通过将消息约束为自描述来实现中间处理：交互在请求之间是无状态的，标准方法和媒体类型用于指示语义和交换信息，并且响应明确指示可缓存性。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于组件是动态连接的，因此它们对特定应用程序操作的排列和功能具有类似于管道和过滤器样式的特征。虽然REST组件通过双向流进行通信，但每个方向的处理是独立的，因此易受流传感器（过滤器）的影响。通用连接器接口允许根据每个请求或响应的属性将组件放置在流上。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以使用中间体和多个分布式源服务器的复杂层次结构来实现服务。REST的无状态特性允许每个交互独立于其他交互，无需了解整个组件拓扑，对于Internet规模的体系结构来说是不可能完成的任务，并且允许组件充当目的地或中介，动态确定按每个请求的目标。连接器只需要在通信范围内了解彼此的存在，但出于性能原因，它们可能会缓存其他组件的存在和功能。\n\n### 3.3.2 连接器视图\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;架构的连接器视图集中于组件之间的通信机制。对于基于REST的体系结构，我们对定义通用资源接口的约束特别感兴趣。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;客户端连接器检查资源标识符，以便为每个请求选择适当的通信机制。例如，客户端可以被配置为当标识符指示它是本地资源时连接到特定代理组件，可能一个充当注释过滤器。同样，客户端可以配置为拒绝对某些标识符子集的请求。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST不限制与特定协议的通信，但它确实限制了组件之间的接口，因此限制了组件之间可能产生的交互和实现假设的范围。例如，Web的主要传输协议是HTTP，但该体系结构还包括对源自预先存在的网络服务器的资源的无缝访问，包括FTP ，Gopher 和WAIS 。与这些服务的交互仅限于REST连接器的语义。这种约束牺牲了其他体系结构的一些优点，例如像WAIS这样的相关性反馈协议的状态交互，以便保留连接器语义的单个通用接口的优点。作为回报，通用接口使得通过单个代理访问多种服务成为可能。如果应用程序需要另一个体系结构的附加功能，它可以作为一个并行运行的独立系统实现和调用这些功能，类似于Web体系结构与“telnet”和“mailto”资源的接口。\n\n### 3.3.3 数据视图\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;体系结构的数据视图揭示了信息流经组件时的应用程序状态。由于REST专门针对分布式信息系统，因此它将应用程序视为信息和控制备选方案的内聚结构，用户可通过该结构执行所需任务。例如，在在线词典中查找单词是一个应用程序，如在虚拟博物馆中巡视，或查看一组课堂笔记以进行考试。每个应用程序都定义了底层系统的目标，可以衡量系统的性能。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;组件交互以动态大小的消息的形式发生。小型或中型消息用于控制语义，但大部分应用程序工作是通过包含完整资源表示的大粒度消息完成的。最常见的请求语义形式是检索资源的表示（例如，HTTP中的“GET”方法），其通常可以被缓存以供以后重用。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST将所有控制状态集中到响应交互所接收的表示中。目标是通过消除服务器的任何需要来提高服务器可扩展性，以保持对当前请求之外的客户端状态的了解。因此，应用程序的状态由其挂起的请求，连接组件的拓扑（其中一些可能是过滤缓冲的数据），这些连接器上的活动请求，响应这些请求的表示的数据流以及这些请求的处理来定义。用户代理收到的表示。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;只要没有未完成的请求，应用程序就会达到稳定状态; 即，它没有待处理的请求，并且对其当前请求集的所有响应已被完全接收或接收到可被视为表示数据流的点。对于浏览器应用程序，此状态对应于“网页”，包括主要表示和辅助表示，例如内嵌图像，嵌入式小程序和样式表。应用稳态的重要性在于它们对用户感知性能和网络请求流量突发性的影响。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;浏览器应用程序的用户感知性能由稳定状态之间的延迟确定：在一个网页上选择超媒体链接与为下一个网页呈现可用信息之间的时间段。因此，浏览器性能的优化集中在减少通信延迟。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于基于REST的体系结构主要通过资源表示的传递进行通信，因此延迟可能受到通信协议的设计和表示数据格式的设计的影响。在接收响应数据时递增地呈现响应数据的能力由媒体类型的设计和每个表示内的布局信息（内嵌对象的视觉尺寸）的可用性确定。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个有趣的观察是，最有效的网络请求是不使用网络的请求。换句话说，重用缓存响应的能力可以显着提高应用程序性能。尽管由于查找开销而使用高速缓存会为每个单独的请求增加一些延迟，但即使一小部分请求导致可用的高速缓存命中，也会显着降低平均请求延迟。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;应用程序的下一个控制状态驻留在第一个请求资源的表示中，因此获得该第一个表示是优先级。因此，通过“先响应并稍后思考”的协议来改进REST交互。换句话说，每个用户操作需要多次交互的协议，以便在发送内容响应之前执行诸如协商功能能力之类的操作，将比发送最有可能首先优先的协议慢，然后提供如果第一个响应不令人满意，客户端要检索的备选列表。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;应用程序状态由用户代理控制和存储，并且可以由来自多个服务器的表示组成。除了使服务器从存储状态的可伸缩性问题中解放出来之外，这允许用户直接操纵状态（例如，Web浏览器的历史），预期对该状态的改变（例如，链接映射和表示的预取）以及跳转。从一个应用程序到另一个应用程序（例如，书签和URI条目对话框）。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，模型应用程序是通过检查并从当前表示集合中的备选状态转换中进行选择而从一个状态移动到下一个状态的引擎。毫不奇怪，这与超媒体浏览器的用户界面完全匹配。但是，该样式并不假设所有应用程序都是浏览器。实际上，通用连接器接口会从服务器隐藏应用程序详细信息，因此用户代理同样可以是为索引服务执行信息检索的自动化机器人，寻找符合特定条件的数据的个人代理或维护蜘蛛忙着巡逻破损的参考文献或修改过的内容。\n\n# 4 经验和评估\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;自1994年以来，REST架构风格已被用于指导现代Web架构的设计和开发。本章介绍了在创建超文本传输协议（HTTP）和统一资源标识符（URI）的Internet标准时应用REST所获得的经验和教训，这两个规范定义了Web上所有组件交互使用的通用接口，以及以libwww-perl客户端库，Apache HTTP Server Project和协议标准的其他实现形式部署这些技术。\n\n## 4.1 标准化web\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;开发REST的动机是为Web应该如何工作创建一个架构模型，以便它可以作为Web协议标准的指导框架。REST已应用于描述所需的Web体系结构，帮助识别现有问题，比较替代解决方案，并确保协议扩展不会违反使Web成功的核心约束。这项工作是作为Internet工程任务组（IETF）和万维网联盟（W3C）为Web定义架构标准的工作的一部分完成的：HTTP，URI和HTML。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Roy Thomas Fielding参与Web标准流程始于1993年末，同时开发了libwww-perl协议库，作为MOMspider的客户端连接器接口。当时，Web架构是由一套非正式的超文本笔记，草拟超文本规范，代表网络的建议功能（其中一些已经实施），以及公共www-talk邮件列表的存档，用于全球WWW项目参与者之间的非正式讨论。与Web实现相比，每个规范都显着过时，主要是由于在引入Mosaic图形浏览器[NCSA]之后Web的快速发展。HTTP中添加了几个实验性扩展以允许代理，但在大多数情况下，协议假定用户代理与HTTP源服务器或遗留系统的网关之间存在直接连接。在缓存，代理或蜘蛛的体系结构中没有意识到，即使实现很容易获得并且无法正常运行。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与此同时，行业内的压力越来越大，要求对Web接口协议的某些版本或版本进行标准化。W3C由Berners-Lee 组成，作为Web架构的智库，提供编写Web标准和参考实现所需的创作资源，但标准化本身由Internet工程任务组管及其关于URI，HTTP和HTML的工作组。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST的第一版是在1994年10月到1995年8月之间开发的，主要是作为一种在我们编写HTTP / 1.0规范和初始HTTP / 1.1提案时传达Web概念的方法。它在接下来的五年中得到了迭代性的改进，并应用于Web协议标准的各种修订和扩展。REST最初被称为“HTTP对象模型”，但该名称通常会导致将其误解为HTTP服务器的实现模型。名称“Representational State Transfer”旨在唤起设计良好的Web应用程序行为的图像：网页网络（虚拟状态机），用户通过选择链接（状态转换）在应用程序中前进，\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST并非旨在捕获Web协议标准的所有可能用途。HTTP和URI的应用程序与分布式超媒体系统的应用程序模型不匹配。然而，重要的一点是REST确实捕获了分布式超媒体系统的所有这些方面，这些方面被认为是Web的行为和性能要求的核心，因此优化模型中的行为将导致部署的Web中的最佳行为建筑。换句话说，REST针对常见情况进行了优化，以便适用于Web体系结构的约束也将针对常见情况进行优化。\n\n## 4.2 REST应用于URI\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;统一资源标识符（URI）既是Web架构中最简单的元素，也是最重要的元素。URI已被许多名称所知：WWW地址，通用文档标识符，通用资源标识符，最后是统一资源定位符（URL）和名称（URN的组合。除了它的名字之外，URI语法自1992年以来一直保持相对不变。但是，Web地址的规范也定义了我们所说的资源的范围和语义，资源自早期的Web架构以来已经发生了变化。REST用于定义URI标准的术语资源，以及通过其表示操作资源的通用接口的整体语义。\n\n### 4.2.1 资源的重新定义\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;早期的Web架构将URI定义为文档标识符。指示作者根据文档在网络上的位置定义标识符。然后可以使用Web协议来检索该文档。然而，由于许多原因，这一定义被证明是不令人满意的。首先，它表明作者正在识别传输的内容，这意味着只要内容发生变化，标识符就会发生变化。其次，存在许多与服务而不是文档相对应的地址 - 作者可能打算将读者引导到该服务，而不是通过先前访问该服务的任何特定结果。最后，在某些时间段存在与文档不对应的地址，\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST中资源的定义基于一个简单的前提：标识符应尽可能不经常更改。因为Web使用嵌入式标识符而不是链接服务器，所以作者需要一个与超媒体引用所关注的语义紧密匹配的标识符，允许引用保持静态，即使访问该引用的结果可能随时间而变化。REST通过将资源定义为作者想要识别的语义来实现这一点，而不是在创建引用时对应于那些语义的值。然后将其留给作者以确保为引用选择的标识符确实标识了预期的语义。\n\n### 4.2.2 操纵阴影\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;定义资源使得URI标识概念而不是文档会给我们留下另一个问题：用户如何访问，操作或转移概念，以便在选择超文本链接时可以获得有用的东西？REST通过定义被操纵为被识别资源的表示的事物而不是资源本身来回答该问题。源服务器维护从资源标识符到对应于每个资源的表示集的映射。因此，通过通过资源标识符定义的通用接口传送表示来操纵资源。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST对资源的定义源于Web的核心要求：跨多个信任域独立创建互连超文本。强制接口定义与接口要求相匹配会导致协议看起来模糊，但这只是因为被操作的接口只是接口而不是实现。协议特定于应用程序操作的意图，但接口背后的机制必须决定该意图如何影响资源映射到表示的底层实现。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;信息隐藏是激发REST统一接口的关键软件工程原则之一。由于客户端仅限于表示的操作而不是直接访问资源的实现，因此可以以命名机构所需的任何形式构造实现，而不会影响可能使用其表示的客户端。另外，如果在访问资源时存在多个资源表示，则可以使用内容选择算法来动态地选择最适合该客户端的能力的表示。当然，缺点是远程创作资源并不像文件的远程创作那样简单。\n\n### 4.2.3 远程创作\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过Web的统一接口进行远程创作的挑战是由于客户端可以检索的表示与可能在服务器上用于存储，生成或检索该表示的内容的机制之间的分离。单个服务器可以将其命名空间的某些部分映射到文件系统，而文件系统又映射到可以映射到磁盘位置的inode的等效物，但是那些底层机制提供了将资源与一组表示相关联的方法。而不是识别资源本身。许多不同的资源可以映射到相同的表示，而其他资源可能根本没有映射。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了创作现有资源，作者必须首先获取特定的源资源URI：绑定到目标资源的处理程序底层表示的URI集。资源并不总是映射到单个文件，但是所有非静态资源都是从其他一些资源派生的，通过遵循派生树，作者最终可以找到所有必须编辑的源资源，以便修改资源的表示。这些相同的原则适用于任何形式的派生表示，无论是来自内容协商，脚本，servlet，托管配置，版本控制等。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;资源不是存储对象。资源不是服务器用于处理存储对象的机制。资源是概念映射 - 服务器接收标识符（标识映射）并将其应用于其当前映射实现（通常是特定于集合的深层树遍历和/或散列表的组合）以查找当前负责的处理程序然后，实现和处理程序实现根据请求内容选择适当的操作+响应。所有这些特定于实现的问题都隐藏在Web界面之后; 它们的性质不能由只能通过Web界面访问的客户端承担。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如，考虑当网站在用户群中增长并决定用基于XOS平台的旧的Brand X服务器替换在FreeBSD上运行的新Apache服务器时会发生什么。磁盘存储硬件已更换。操作系统已被替换。HTTP服务器已被替换。甚至可以替换为所有内容生成响应的方法。但是，不需要更改的是Web界面：如果设计正确，新服务器上的命名空间可以反映旧服务器上的命名空间，这意味着从客户端的角度来看，它只知道资源而不知道它们是如何实现的除了网站改进的稳健性之外，没有任何改变。\n\n### 4.2.4 将语义绑定到URI\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上所述，资源可以具有许多标识符。换句话说，当用于访问服务器时，可能存在两个或更多个具有等效语义的不同URI。也可能有两个URI导致在访问服务器时使用相同的机制，但这些URI标识两个不同的资源，因为它们并不意味着相同的事情。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;语义是分配资源标识符并用表示填充这些资源的行为的副产品。在任何时候，服务器或客户端软件都不需要知道或理解URI的含义 - 它们只是作为一个管道，资源的创建者（人类命名机构）可以通过该管道将表示与由表示的语义相关联。 URI。换句话说，服务器上没有资源; 只是通过资源定义的抽象接口提供答案的机制。这可能看起来很奇怪，但这是使Web在许多不同实现中工作的本质。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每个工程师的本质是根据将用于组成成品的组件的特征来定义事物。网络不是这样的。Web体系结构包括组件之间通信模型的约束，基于应用程序操作期间每个组件的角色。这可以防止组件假设超出资源抽象的任何内容，从而隐藏抽象接口任一侧的实际机制。\n\n### 4.2.5 URI中的REST不匹配\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与大多数现实世界系统一样，并非所部署的Web体系结构的所有组件都遵循其体系结构设计中存在的每个约束。REST既被用作定义架构改进的手段，也用于识别架构不匹配。当由于无知或疏忽而部署了违反架构约束的软件实现时，会发生不匹配。虽然通常无法避免不匹配，但可以在它们变得标准化之前识别它们。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然URI设计符合REST的标识符架构概念，但仅凭语法不足以迫使命名机构根据资源模型定义自己的URI。滥用的一种形式是包括标识超媒体响应表示所引用的所有URI中的当前用户的信息。此类嵌入式用户ID可用于维护服务器上的会话状态，通过记录其操作来跟踪用户行为，或跨多个操作（例如，Hyper-G的网关[ 84 ]）携带用户首选项。但是，通过违反REST的约束，这些系统还会导致共享缓存变得无效，降低服务器可伸缩性，并在用户与其他人共享这些引用时导致不良影响。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当软件试图将Web视为分布式文件系统时，会发生与REST资源接口的另一个冲突。由于文件系统公开其信息的实现，因此存在将该信息“镜像”到多个站点的工具，作为负载平衡和将内容重新分布到用户附近的手段。但是，他们只能这样做，因为文件具有一组固定的语义（一个命名的字节序列），可以轻松复制。相反，尝试将Web服务器的内容镜像为文件将失败，因为资源接口并不总是与文件系统的语义匹配，并且因为数据和元数据都包含在表示的语义中，并且对于表示的语义很重要。Web服务器内容可以在远程站点复制，\n\n## 4.3 REST应用于HTTP\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;超文本传输协议（HTTP）在Web体系结构中具有特殊的作用，它既是Web组件之间通信的主要应用程序级协议，也是专门为资源表示传输而设计的唯一协议。与URI不同，为了支持现代Web架构，需要进行大量更改。HTTP实现的开发人员在采用提议的增强功能时一直保守，因此扩展需要在部署之前进行验证并进行标准审查。REST用于识别现有HTTP实现的问题，将该协议的可互操作子集指定为HTTP / 1.0 [ 19 ]，分析HTTP / 1.1的建议扩展[ 42]]，并提供部署HTTP / 1.1的激励理由。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由REST识别的HTTP中的关键问题区域包括规划新协议版本的部署，将消息解析与HTTP语义和底层传输层（TCP）分离，区分权威和非权威响应，细粒度控制缓存，以及无法自我描述的协议的各个方面。REST还被用于模拟基于HTTP的Web应用程序的性能，并预测这些扩展对持久连接和内容协商的影响。最后，REST已被用于将标准化HTTP扩展的范围限制为适合体系结构模型的范围，而不是允许滥用HTTP的应用程序同等地影响标准。\n\n### 4.3.1 可扩展性\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST的主要目标之一是支持在已部署的体系结构中逐步和分散的更改部署。通过引入版本控制要求和规则来修改HTTP以支持该目标，以扩展每个协议的语法元素。\n\n#### 4.3.1.1 协议版本控制\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP是一系列协议，由主要版本号和次要版本号区分，它们共享名称主要是因为它们对应于直接与基于“http”URL命名空间的服务通信时所期望的协议。连接器必须遵守每条消息中包含的HTTP版本协议元素的约束。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;消息的HTTP版本表示发送方的协议功能以及正在发送的消息的总兼容性（主要版本号）。这允许客户端在发出正常的HTTP / 1.1请求时使用简化的（HTTP / 1.0）特征子集，同时向接收者指示它能够支持完整的HTTP / 1.1通信。换句话说，它在HTTP规模上提供了一种暂定形式的协议协商。尽管某些客户端或服务器是链的一部分，但请求/响应链上的每个连接都可以在其最佳协议级别运行。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;协议的目的是服务器应始终使用它在客户端请求消息的相同主要版本中理解的协议的最高次要版本进行响应。限制是服务器不能使用更高级别协议的那些可选功能，这些功能被禁止发送到这样的旧版客户端。协议没有必需的功能，不能与该主要版本中的所有其他次要版本一起使用，因为这将是不兼容的更改，因此需要更改主要版本。可以依赖于次要版本号更改的HTTP的唯一功能是由通信中的直接邻居解释的那些功能，因为HTTP不要求中间组件的整个请求/响应链说出相同的版本。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;存在这些规则以帮助部署多个协议修订并防止HTTP架构师忘记协议的部署是其设计的重要方面。他们通过简化协议的兼容更改和不兼容的更改来实现这一点。兼容的更改易于部署，并且可以在协议流内实现差异的通信。不兼容的更改难以部署，因为它们需要在协议流开始之前确定接受协议。\n\n#### 4.3.1.2 可扩展协议元素\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP包括许多单独的命名空间，每个命名空间都有不同的约束，但所有这些命名空间都共享无限制可扩展的要求。一些命名空间由不同的Internet标准管理，并由多个协议共享（例如，URI方案[ 21 ]，媒体类型[ 48 ]，MIME头字段名[ 47 ]，字符集值，语言标签），而其他名称由HTTP，包括方法名称的命名空间，响应状态代码，非MIME标头字段名称以及标准HTTP标头字段中的值。由于早期的HTTP没有为如何部署这些命名空间中的更改定义一套一致的规则，因此这是规范工作所解决的首批问题之一。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP请求语义由请求方法名称表示。只要可以在客户端，服务器和可能位于它们之间的任何中介之间共享可标准化的语义集，就允许方法扩展。不幸的是，早期的HTTP扩展，特别是HEAD方法，使HTTP响应消息的解析依赖于知道请求方法的语义。这导致了部署矛盾：如果接收方需要知道方法的语义，然后才能由中介安全地转发，则必须先更新所有中介，然后才能部署新方法。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过将用于解析和转发HTTP消息的规则与与新HTTP协议元素相关联的语义分开来解决此部署问题。例如，HEAD是Content-Length头字段具有除表示消息体长度之外的含义的唯一方法，并且没有新方法可以更改消息长度计算。GET和HEAD也是条件请求头字段具有缓存刷新语义的唯一方法，而对于所有其他方法，它们具有前置条件的含义。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同样，HTTP需要一个通用规则来解释新的响应状态代码，这样可以部署新的响应而不会显着损害旧的客户端。因此，我们扩展了以下规则：每个状态代码属于由其三位十进制数的第一个数字表示的类：100-199表示该消息包含临时信息响应，200-299表示请求成功，300 -399表示请求需要重定向到另一个资源，400-499表示客户端发出不应该重复的错误，500-599表示服务器遇到错误，但客户端可能会更好稍后回复（或通过其他服务器）。如果收件人不理解给定消息中状态代码的特定语义，然后他们必须以与其类中的x00代码相同的方式对待它。与方法名称的规则一样，此可扩展性规则对当前体系结构提出了要求，以便预测未来的更改。因此，可以将更改部署到现有架构上，而不必担心不良组件反应。\n\n#### 4.3.1.3 升级\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在HTTP / 1.1中添加Upgrade头字段通过允许客户端在较旧的协议流中进行通信时宣传其对更好协议的意愿来减少部署不兼容更改的难度。升级是专门添加的，以支持选择性地替换HTTP / 1.x与其他未来的协议，这些协议可能对某些任务更有效。因此，HTTP不仅支持内部可扩展性，还在活动连接期间完成自身的替换。如果服务器支持改进的协议并希望切换，则它只响应101状态并继续，就像在该升级的协议中接收到请求一样。\n\n### 4.3.2 自描述信息\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST将组件之间的消息约束为自描述，以支持交互的中间处理。但是，早期HTTP的某些方面无法进行自我描述，包括请求中缺少主机标识，无法在语法上区分消息控制数据和表示元数据，无法区分仅用于直接连接对等的控制数据与针对所有收件人的元数据，缺乏对强制性扩展的支持，以及需要元数据来描述具有分层编码的表示。\n\n#### 4.3.2.1 主机\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;早期HTTP设计中最严重的错误之一是决定不发送作为请求消息目标的完整URI，而是仅发送那些未用于设置连接的部分。假设服务器将根据连接的IP地址和TCP端口知道自己的命名权限。但是，这未能预料到单个服务器上可能存在多个命名权限，这成为一个关键问题，因为Web以指数速率增长，而新域名（http URL命名空间内命名权限的基础）远远超出了可用性新的IP地址。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为HTTP / 1.0和HTTP / 1.1定义和部署的解决方案是在请求消息的主机头字段中包含目标URL的主机信息。此功能的部署被认为非常重要，以至于HTTP / 1.1规范要求服务器拒绝任何不包含主机字段的HTTP / 1.1请求。结果，现在存在许多大型ISP服务器，其在单个IP地址上运行数万个基于名称的虚拟主机网站。\n\n#### 4.3.2.2 分层编码\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP继承了其用于描述多用途Internet邮件扩展（MIME）中的表示元数据的语法。MIME不定义分层媒体类型，而是仅在Content-Type字段值中包含最外层媒体类型的标签。然而，这防止接收者在不解码层的情况下确定编码消息的性质。早期的HTTP扩展通过在Content-Encoding字段中单独列出外部编码并将最内层媒体类型的标签放在Content-Type中来解决此问题。这是一个糟糕的设计决策，因为它改变了Content-Type的语义而不改变其字段名称，导致每当旧用户代理遇到扩展时就会出现混淆。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;更好的解决方案是继续将Content-Type视为最外层媒体类型，并使用新字段来描述该类型中的嵌套类型。不幸的是，第一次扩展是在发现故障之前部署的。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST确实需要另外一层编码：连接器放置在消息上以便提高其在网络上的可转移性。这个新层（称为转移编码，参考MIME中的类似概念）允许对消息进行编码以进行传输，而不暗示该表示是按性质编码的。无论出于何种原因，转移代理都可以添加或删除转移编码，而无需更改表示的语义。\n\n#### 4.3.2.3 语义独立性\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上所述，HTTP消息解析已与其语义分离。消息解析（包括查找和汇总头字段）完全独立于解析头字段内容的过程。通过这种方式，中介可以快速处理和转发HTTP消息，并且可以在不破坏现有解析器的情况下部署扩展。\n\n#### 4.3.2.4 运输独立性\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;早期的HTTP，包括HTTP / 1.0的大多数实现，使用底层传输协议作为发送响应消息结束信号的手段。服务器将通过关闭TCP连接来指示响应消息正文的结束。不幸的是，这在协议中造成了严重的失败情况：客户端无法区分已完成的响应和因某些错误的网络故障而被截断的响应。为了解决这个问题，Content-Length头字段在HTTP / 1.0中被重新定义，以指示消息体长度（以字节为单位），每当事先知道长度，并且“chunked”传输编码被引入HTTP / 1.1。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分块编码允许在其生成开始时（当发送报头字段时）大小未知的表示使其边界由一系列块描绘，这些块在发送之前可以单独地大小。它还允许在消息末尾将元数据作为预告片发送，从而在生成消息时在原点创建可选元数据，而不会增加响应延迟。\n\n#### 4.3.2.5 大小限制\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对应用层协议的灵活性的常见障碍是倾向于过度指定协议参数的大小限制。尽管在协议的实现中总是存在一些实际限制（例如，可用存储器），但是在协议内指定那些限制将所有应用限制到相同的限制，而不管它们的实现如何。结果通常是最低公分母协议，不能超出其原始创建者的设想。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP协议对URI的长度，头字段的长度，表示的长度或由项列表组成的任何字段值的长度没有限制。尽管较旧的Web客户端存在一个众所周知的URI，其中包含超过255个字符的问题，但只需要注意HTTP规范中的问题而不是要求所有服务器都受到限制。这不会使协议最大化的原因是受控上下文（例如Intranet）内的应用程序可以通过替换旧组件来避免这些限制。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然我们不需要发明人为限制，但HTTP / 1.1确实需要定义一组适当的响应状态代码，以指示给定协议元素何时对服务器进行处理时间过长。这些响应代码是在Request-URI条件太长，标题字段太长，正文太长的情况下添加的。遗憾的是，客户端无法向服务器指示它可能具有资源限制，这在资源受限设备（例如PDA）尝试使用HTTP而没有特定于设备的中介调整通信时会导致问题。\n\n#### 4.3.2.6 缓存限制\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于REST试图平衡对高效，低延迟行为的需求与对语义透明缓存行为的需求，因此HTTP允许应用程序确定缓存要求而不是将其硬编码到协议本身中至关重要。协议要做的最重要的事情就是完全准确地描述正在传输的数据，这样就不会让任何应用程序误以为它实际上有其他东西时会有一件事情。HTTP / 1.1通过添加Cache-Control，Age，Etag和Vary头字段来实现此目的。\n\n#### 4.3.2.7 内容协商\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所有资源都将请求（包括方法，标识符，请求标题字段，有时是表示）映射到响应（由状态代码，响应标头字段，有时是表示）组成。当HTTP请求映射到服务器上的多个表示时，服务器可以与客户进行内容协商，以确定哪个最符合客户的需求。这实际上比谈判更像是一个“内容选择”过程。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然有几个部署的内容协商实现，但它没有包含在HTTP / 1.0规范中，因为在发布时没有可互操作的实现子集。这部分是由于NCSA Mosaic中的实施不佳，无论资源的可转让性如何，都会在每个请求的头字段中发送1KB的偏好信息[ 125 ]。由于远低于所有URI的0.01％在内容中可协商，因此结果显着增加了请求延迟以获得非常小的增益，这导致后来的浏览器无视HTTP / 1.0的协商功能。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当服务器根据请求头字段的值或上述正常请求参数外部的某些内容改变特定请求方法*标识符*状态代码组合的响应表示时，发生抢占（服务器驱动）协商。发生这种情况时，客户端需要得到通知，以便缓存可以知道何时对于将来的请求使用特定的缓存响应在语义上是透明的，并且还使得用户代理可以提供比通常一次发送的更详细的首选项。它知道它们对收到的回复有影响。HTTP / 1.1为此目的引入了Vary头字段。Vary只列出响应可能变化的请求标头字段维度。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在抢先协商中，用户代理告诉服务器它能够接受什么。然后，服务器应该选择与用户代理声称其功能最匹配的表示。然而，这是一个不易处理的问题，因为它不仅需要关于UA将接受什么的信息，而且还需要它接受每个特征的程度以及用户打算表达的目的。例如，想要在屏幕上查看图像的用户可能更喜欢简单的位图表示，但是如果他们打算将其发送到打印机，则具有相同浏览器的相同用户可能更喜欢PostScript表示。它还取决于用户根据自己的个人内容偏好正确配置他们的浏览器。简而言之，\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP / 1.1增加了被动（代理驱动）协商的概念。在这种情况下，当用户代理请求协商的资源时，服务器以可用的表示列表进行响应。然后，用户代理可以根据自己的能力和目的选择哪一个最佳。关于可用表示的信息可以通过响应数据内部的单独表示（例如，300响应）来提供（例如，条件HTML），或者作为“最可能”响应的补充。后者最适合Web，因为只有当用户代理决定其他变体之一会更好时，才需要额外的交互。反应式协商只是普通浏览器模型的自动反映，这意味着它可以充分利用REST的所有性能优势。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;抢先式和被动式协商都难以传达表示维度的实际特征（例如，如何说浏览器支持HTML表而不是INSERT元素）。然而，反应式协商具有明显的优点，即不必在每个请求上发送首选项，具有更多的上下文信息，在面对备选方案时可以做出决策，而不是干扰缓存。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第三种形式的协商，透明协商[ 64 ]，是中间缓存代表其他代理充当代理的许可，用于选择更好的表示并发起检索该表示的请求。该请求可以通过另一个缓存命中在内部解析，因此可能不会进行额外的网络请求。但是，在这样做时，它们正在执行服务器驱动的协商，因此必须添加适当的Vary信息，以便其他出站缓存不会混淆。\n\n### 4.3.3 性能\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP / 1.1侧重于改进组件之间通信的语义，但是对用户感知性能也有一些改进，尽管受到与HTTP / 1.0的语法兼容性要求的限制。\n\n#### 4.3.3.1 持久连接\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然早期HTTP的单个请求/响应是针对简单实现的每个连接行为，但由于每个交互设置成本的开销和TCP的慢启动拥塞控制算法的性质，导致底层TCP传输的使用效率低下[ 63]，125 ]。因此，提出了几个扩展，以在单个连接中组合多个请求和响应。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一个提议是定义一组新的方法，用于在单个消息（MGET，MHEAD等）中封装多个请求，并将响应作为MIME多部分返回。这被拒绝了，因为它违反了几个REST约束。首先，客户端需要知道在第一个请求被写入网络之前它想要打包的所有请求，因为请求主体必须由初始请求头字段中设置的内容长度字段进行长度分隔。其次，中介必须提取每条消息，以确定它可以在本地满足哪些消息。最后，它有效地使请求方法的数量加倍，并使选择性地拒绝访问某些方法的机制复杂化。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;相反，我们采用了一种持久连接形式，它使用长度分隔的消息，以便在单个连接上发送多个HTTP消息。对于HTTP / 1.0，这是使用Connection头字段中的“keep-alive”指令完成的。不幸的是，这通常不起作用，因为标题字段可以由中介转发给其他不了解保持活动的中介，从而导致死锁条件。HTTP / 1.1最终决定使持久连接成为默认值，从而通过HTTP版本值表明它们的存在，并且仅使用connection-directive“close”来反转默认值。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;值得注意的是，只有在将HTTP消息重新定义为自描述且独立于底层传输协议之后，才能实现持久连接。\n\n#### 4.3.3.2 直写缓存\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP不支持回写缓存。HTTP缓存不能假定通过它写入的内容与从该资源的后续请求可检索的内容相同，因此它无法缓存PUT请求主体并将其重用于以后的GET响应。此规则有两个原因：1）可能在幕后生成元数据，2）无法从PUT请求确定以后GET请求的访问控制。但是，由于使用Web的写入操作极少，因此缺少回写式高速缓存不会对性能产生重大影响。\n\n### 4.3.4 HTTP中的REST不匹配\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP中存在一些架构与REST不匹配，一些是由于部署在标准流程外部的第三方扩展，另一些是由于必须保持与部署的HTTP / 1.0组件兼容。\n\n#### 4.3.4.1 区分非权威影响\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP中仍然存在的一个缺点是，没有一致的机制来区分由原始服务器响应当前请求而生成的权威响应，以及从中间设备或缓存获取的非权威响应，而无需访问原始服务器。这种区别对于需要权威响应的应用程序非常重要，例如健康行业中使用的安全关键信息设备，以及返回错误响应并且客户端想知道错误是否源于原点的那些时间或某些中间人。尝试使用其他状态代码解决此问题并未成功，因为权威性质通常与响应状态正交。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP / 1.1确实添加了一种机制来控制缓存行为，从而可以指示对权威响应的需求。请求消息上的“no-cache”指令要求任何缓存将请求转发到源服务器，即使它具有所请求内容的缓存副本。这允许客户端刷新已知已损坏或过时的缓存副本。但是，定期使用此字段会干扰缓存的性能优势。更通用的解决方案是，只要操作不会导致联系原始服务器，就要求将响应标记为非权威。为此目的（和其他）在HTTP / 1.1中定义了一个警告响应头字段，但它在实践中尚未广泛实现。\n\n#### 4.3.4.2 Cookies\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;举例说明对协议进行了不适当的扩展以支持与通用接口所需属性相矛盾的功能，即以HTTP cookie的形式引入站点范围的状态信息。Cookie交互无法与REST的应用程序状态模型匹配，通常会导致典型浏览器应用程序混淆。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP cookie是不透明的数据，可以由源服务器分配给用户代理，方法是将其包含在Set-Cookie响应头字段中，目的是用户代理应该在将来对该服务器的所有请求中包含相同的cookie直到它被替换或过期。此类cookie通常包含一组特定于用户的配置选项，或者在将来的请求中与服务器数据库匹配的令牌。问题在于，cookie被定义为附加到对给定资源标识符集的任何未来请求，通常包含整个站点，而不是与浏览器上的特定应用程序状态（当前呈现的表示集合）相关联。当浏览器的历史功能（“返回”）随后用于备份到cookie反映的视图之前的视图，浏览器的应用程序状态不再与cookie中表示的存储状态匹配。因此，发送到同一服务器的下一个请求将包含一个错误表示当前应用程序上下文的cookie，从而导致双方混淆。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cookie还违反了REST，因为它们允许在没有充分识别其语义的情况下传递数据，从而成为安全和隐私的关注点。Cookie与Referer [sic]标题字段的组合使得跟踪用户在站点之间浏览时成为可能。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，Web上基于cookie的应用程序永远不可靠。应该通过匿名身份验证和真正的客户端状态来完成相同的功能。通过明智地使用上下文设置URI而不是cookie，可以更有效地实现涉及首选项的状态机制，其中明智意味着每个状态一个URI而不是由于嵌入用户id而无限数量的URI。同样，通过在超媒体数据格式中定义购物项的语义，允许用户代理选择和存储这些项，可以更有效地实现使用cookie来识别服务器端数据库中的用户特定“购物篮”。在他们自己的客户端购物篮中，配有一个URI，用于在客户准备购买时签出。\n\n#### 4.3.4.3 强制扩展\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP标头字段名称可以随意扩展，但只有在它们包含的信息不是正确理解消息时才需要扩展。强制标头字段扩展需要主要协议修订或对方法语义的实质性更改，例如[ 94]。这是现代Web架构的一个方面，它尚未与REST架构风格的自描述消息传递约束相匹配，主要是因为在现有HTTP语法中实现强制扩展框架的成本超过了我们可能从中获得的任何明显好处。强制性扩展。但是，当对语法的向后兼容性的现有约束不再适用时，期望在HTTP的下一个主要修订版中支持必需的字段名称扩展是合理的。\n\n#### 4.3.4.4 混合元数据\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP旨在通过网络连接扩展通用连接器接口。因此，它旨在匹配该接口的特征，包括将参数描绘为控制数据，元数据和表示。但是，HTTP / 1.x协议系列的两个最重要的限制是它无法在语法上区分表示元数据和消息控制信息（都作为头字段传输），并且不允许元数据有效地分层以实现消息完整性检查。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST在标准化过程的早期阶段将这些限制在协议中，预计它们会导致其他功能部署中的问题，例如持久连接和摘要式身份验证。开发了变通方法，包括添加Connection头字段以识别中间人转发不安全的每连接控制数据，以及标头字段摘要的规范处理算法。\n\n#### 4.3.4.5 MIME语法\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP继承了MIME 的消息语法，以保持与其他Internet协议的通用性，并重用许多标准化字段来描述消息中的媒体类型。不幸的是，MIME和HTTP具有非常不同的目标，并且语法仅针对MIME的目标而设计。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在MIME中，用户代理正在向未知的接收者发送一堆信息，这些信息旨在被视为一个连贯的整体，而这些信息从未直接与之交互。MIME假定代理希望在一条消息中发送所有信息，因为通过Internet邮件发送多条消息的效率较低。因此，构造MIME语法以将邮件打包在部件或多部件中，这与邮政运营商将包裹包装在额外纸张中的方式非常相似。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在HTTP中，除了安全封装或打包存档之外，在单个消息中打包不同对象没有任何意义，因为对尚未缓存的那些文档进行单独请求更有效。因此，HTTP应用程序使用HTML等媒体类型作为对“包”的引用的容器 - 然后用户代理可以选择要作为单独请求检索的包的哪些部分。尽管HTTP可能使用多部分包，其中第一部分之后仅包含非URI资源，但对它的需求并不大。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MIME语法的问题在于它假设传输是有损的，故意破坏换行符和内容长度之类的东西。因此，对于不基于有损传输的任何系统，语法都是冗长且低效的，这使得它不适合HTTP。由于HTTP / 1.1具有支持不兼容协议部署的能力，因此对于下一个主要版本的HTTP，保留MIME语法不是必需的，即使它可能会继续使用许多标准化协议元素来表示元数据。\n\n### 4.3.5 匹配对请求的响应\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在描述哪个响应属于哪个请求时，HTTP消息无法自我描述。早期的HTTP基于每个连接的单个请求和响应，因此不需要消息控制数据将响应绑定回调用它的请求。因此，请求的排序决定了响应的顺序，这意味着HTTP依赖于传输连接来确定匹配。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP / 1.1虽然被定义为独立于传输协议，但仍假定通信发生在同步传输上。通过添加请求标识符，可以轻松扩展它以处理异步传输，例如电子邮件。这种扩展对于广播或多播情况下的代理是有用的，其中可以在与请求的信道不同的信道上接收响应。此外，在许多请求待处理的情况下，它将允许服务器选择响应被传送的顺序，从而首先发送更小或更重要的响应。\n\n## 4.4 技术转让\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然REST对Web标准的创作有最直接的影响，但是通过以商业级实现的形式部署标准来验证其作为架构设计模型的使用。\n\n### 4.4.1 libwww-perl的实践经验\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我参与Web标准的定义始于维护机器人MOMspider 及其相关协议库libwww-perl的开发。以Tim Berners-Lee开发的原始libwww和CERN的WWW项目为模型，libwww-perl提供了一个统一的界面，用于为使用Perl语言编写的客户端应用程序发出Web请求和解释Web响应。它是第一个独立于原始CERN项目开发的Web协议库，反映了Web接口比旧代码库中更现代的解释。该接口成为设计REST的基础。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;libwww-perl由单个请求接口组成，该接口使用Perl的自我评估代码功能，根据请求的URI方案动态加载适当的传输协议包。例如，当要求在URL <http://www.ebuilt.com/>上发出“GET”请求时，libwww-perl将从URL（“http”）中提取该方案并使用它来构建一个调用到wwwhttp'request（），使用所有类型资源（HTTP，FTP，WAIS，本地文件等）共有的接口。为了实现这个通用接口，库以与HTTP代理大致相同的方式处理所有调用。它提供了一个使用Perl数据结构的接口，它具有与HTTP请求相同的语义，而不管资源的类型如何。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;libwww-perl展示了通用接口的优点。在最初发布的一年内，超过600名独立软件开发人员使用该库创建自己的客户端工具，从命令行下载脚本到成熟的浏览器。它目前是大多数Web系统管理工具的基础。\n\n### 4.4.2 Apache的实践经验\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于HTTP的规范工作开始采用完整规范的形式，我们需要服务器软件，既可以有效地演示建议的标准协议，也可以作为有价值扩展的测试平台。当时，最受欢迎的HTTP服务器（httpd）是由Rob McCool在伊利诺伊大学厄巴纳 - 香槟分校（NCSA）的国家超级计算应用中心开发的公共领域软件。然而，在1994年中期Rob离开NCSA后，开发工作陷入停滞，许多网站管理员开发了自己的扩展和错误修复，需要共同分发。我们一群人创建了一个邮件列表，目的是将我们的更改作为原始来源的“补丁”进行协调。在此过程中，我们创建了Apache HTTP Server Project 。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Apache项目是一项协作软件开发工作，旨在为HTTP服务器创建一个强大的，商业级的，功能齐全的开源软件实现。该项目由位于世界各地的一组志愿者共同管理，使用互联网和网络来交流，规划和开发服务器及其相关文档。这些志愿者被称为Apache Group。最近，该组织成立了非营利组织Apache Software Foundation，作为支持Apache开源项目持续开发的法律和金融伞形组织。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Apache以其强大的行为而闻名，以响应互联网服务的各种需求以及严格实施HTTP协议标准。我在Apache Group中担任“协议警察”，为核心HTTP解析函数编写代码，通过解释标准支持其他人的工作，并充当Apache开发人员对“正确实施方法”的观点的倡导者HTTP“在标准论坛内。本章中描述的许多课程都是在Apache项目中创建和测试HTTP的各种实现，并将协议背后的理论置于Apache Group的批判性审核中。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Apache httpd被广泛认为是最成功的软件项目之一，也是第一个主导市场的开源软件产品之一，其中存在重大的商业竞争。2000年7月Netcraft对公共互联网网站的调查发现，基于Apache软件的网站超过2000万个，占所有被调查网站的65％以上[http://www.netcraft.com/survey/]。Apache是第一个支持HTTP / 1.1协议的主要服务器，通常被认为是测试所有客户端软件的参考实现。Apache Group获得1999年ACM软件系统奖，以表彰我们对Web架构标准的影响。\n\n### 4.4.3 部署URI和HTTP/1.1兼容软件\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除了Apache之外，许多其他商业和开源项目都采用并部署了基于现代Web架构协议的软件产品。虽然这可能只是巧合，但微软Internet Explorer在第一个实现HTTP / 1.1客户端标准的主要浏览器之后不久便在Web浏览器市场份额中超越了Netscape Navigator。此外，在标准化过程中定义的许多单独的HTTP扩展（例如Host头字段）现在已经达到了通用部署。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST架构风格成功地指导了现代Web架构的设计和部署。到目前为止，新标准的引入并没有出现重大问题，尽管它们与传统的Web应用程序一起进行了逐步和分散的部署。此外，新标准对Web的健壮性产生了积极影响，并通过缓存层次结构和内容分发网络实现了提高用户感知性能的新方法。\n\n## 4.5 架构课程\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从现代Web架构和REST识别的问题中可以学到许多一般的架构课程。\n### 4.5.1 基于网络的API优点\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现代Web与其他中间件的区别在于它使用HTTP作为基于网络的应用程序编程接口（API）的方式。情况并非总是如此。早期的Web设计使用了一个库包CERN libwww作为所有客户端和服务器的单一实现库。CERN libwww提供了一个基于库的API，用于构建可互操作的Web组件。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于库的API提供了一组代码入口点和相关的符号/参数集，以便程序员可以使用其他人的代码来执行维护类似系统之间的实际接口的脏工作，前提是程序员遵循架构和语言该代码附带的限制。假设通信的所有方面都使用相同的API，因此接口的内部仅对API开发人员而非应用程序开发人员很重要。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;单一图书馆方法于1993年结束，因为它与参与开发网络的组织的社会动态不匹配。当NCSA的团队通过比CERN更大的开发团队增加Web开发的速度时，libwww源代码被“分叉”（分成单独维护的代码库），以便NCSA的人们不必等待欧洲核子研究中心追赶他们的进步。与此同时，像我这样的独立开发人员开始为CERN代码尚未支持的语言和平台开发协议库。Web的设计必须从参考协议库的开发转向基于网络的API的开发，在多个平台和实现之间扩展Web的所需语义。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于网络的API是一种线上语法，具有定义的语义，用于应用程序交互。除了需要读取/写入网络之外，基于网络的API不会对应用程序代码施加任何限制，但会对可以通过接口有效通信的语义集施加限制。从好的方面来说，性能仅受协议设计的限制，而不受该设计的任何特定实现的限制。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于库的API为程序员提供了更多功能，但这样做会产生比任何一个系统所需的更多复杂性和包袱，在异构网络中的可移植性更低，并且总是导致通用性优于性能。作为一种副作用，它还会导致懒惰的开发（将所有内容归咎于API代码）以及未能解释通信中其他方的非合作行为。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，重要的是要记住，任何架构都涉及各种层，包括现代Web的层。像Web这样的系统使用一个库API（套接字）来访问几个基于网络的API（例如，HTTP和FTP），但套接字API本身位于应用层之下。同样，libwww是一个有趣的交叉品种，它已经演变成基于库的API，用于访问基于网络的API，因此提供可重用的代码，而不假设其他通信应用程序也在使用libwww。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这与CORBA 等中间件形成鲜明对比。由于CORBA只允许通过ORB进行通信，因此其传输协议IIOP对于各方的通信过多。HTTP请求消息包括标准化应用程序语义，而IIOP消息则不包括。IIOP中的“请求”令牌仅提供方向性，以便ORB可以根据ORB本身是否应该回复（例如，“LocateRequest”）或者它是否将被对象解释来路由它。语义由对象键和操作的组合表示，它们是特定于对象的，而不是跨所有对象的标准化。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;独立开发人员可以在不使用相同ORB的情况下生成与IIOP请求相同的位，但这些位本身由CORBA API及其接口定义语言（IDL）定义。它们需要由IDL编译器生成的UUID，反映IDL操作签名的结构化二进制内容，以及根据IDL规范定义的回复数据类型。因此，语义不是由网络接口（IIOP）定义的，而是由对象的IDL规范定义的。这是否是一件好事取决于应用程序 - 对于分布式对象，它是必需的，对于Web来说它不是。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为什么这很重要？因为它区分了一个系统，在这个系统中，网络中介可以是有效的代理，而系统最多只能是路由器。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在将消息解释为单元或流时，也可以看到这种差异。HTTP允许收件人或发件人自己决定。CORBA IDL甚至不允许流（但是），但即使它扩展到支持流，通信的两端也将绑定到相同的API，而不是自由使用任何最适合其类型的应用。\n\n### 4.5.2 HTTP不是RPC\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;人们经常错误地将HTTP称为远程过程调用（RPC）机制，因为它涉及请求和响应。RPC与其他形式的基于网络的应用程序通信的区别在于在远程机器上调用过程的概念，其中协议识别过程并向其传递一组固定的参数，然后等待在一个参数内提供的答案。使用相同的接口返回消息。远程方法调用（RMI）类似，只是该过程被标识为{object，method}元组而不是服务过程。Brokered RMI增加了名称服务间接和其他一些技巧，但界面基本相同。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP与RPC的区别不在于语法。它甚至不是使用流作为参数获得的不同特性，但这有助于解释为什么现有的RPC机制不能用于Web。使HTTP明显不同于RPC的原因是请求是使用具有标准语义的通用接口定向到资源的，这些语义可以由中间人解释，也可以由发起服务的机器解释。结果是一个应用程序，它允许独立于信息源的转换和间接层，这对于Internet规模，多组织，无法扩展的信息系统非常有用。相反，RPC机制是根据语言API定义的，而不是基于网络的应用程序。\n\n### 4.5.3 HTTP不是传输协议\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP不是设计为传输协议。它是一种传输协议，其中消息通过传输和操纵这些资源的表示对资源执行操作来反映Web体系结构的语义。使用这个非常简单的接口可以实现广泛的功能，但是需要遵循接口才能使HTTP语义对中间人保持可见。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这就是HTTP通过防火墙的原因。除了WebDAV之外，大多数最近提出的HTTP扩展只是使用HTTP作为一种通过防火墙移动其他应用程序协议的方法，这是一个根本误导的想法。它不仅没有达到防火墙的目的，而且从长远来看也不会起作用，因为防火墙厂商只需要执行额外的协议过滤。因此，在HTTP之上进行这些扩展是没有意义的，因为在这种情况下，HTTP完成的唯一事情是增加遗留语法的开销。HTTP的真正应用将协议用户的动作映射到可以使用HTTP语义表达的东西，从而为服务创建基于网络的API，代理和中介可以在不知道应用程序的情况下理解这些API。\n\n### 4.5.4 媒体类型的设计\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST对建筑风格来说不同寻常的一个方面是它影响Web架构中数据元素定义的程度。\n\n#### 4.5.4.1 基于网络的系统中的应用状态\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST定义了一个预期的应用程序行为模型，它支持简单而强大的应用程序，这些应用程序在很大程度上不受困扰大多数基于网络的应用程序的部分。 但是，这并不能阻止应用程序开发人员引入违反该模型的功能。最常见的违规是关于应用程序状态和无状态交互的约束。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于错误放置应用程序状态而导致的架构不匹配不仅限于HTTP cookie。对超文本标记语言（HTML）引入“框架”引起了类似的混淆。框架允许将浏览器窗口划分为子窗口，每个窗口都有自己的导航状态。子窗口中的链接选择与正常转换无法区分，但生成的响应表示在子窗口中呈现，而不是在完整的浏览器应用程序工作空间中呈现。这很好，前提是没有链接退出用于子窗口处理的信息领域，但是当它确实发生时，用户发现自己正在查看一个楔入另一个应用程序的子上下文中的应用程序。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于帧和cookie，失败的原因是提供了用户代理无法管理或解释的间接应用程序状态。将此信息置于主要表示中的设计，从而通知用户代理如何管理指定的资源域的超媒体工作空间，可以在不违反REST约束的情况下完成相同的任务，同时实现更好的用户界面和减少对缓存的干扰。\n\n#### 4.5.4.2 增量处理\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过将延迟减少作为架构目标，REST可以根据用户感知的性能区分媒体类型（表示的数据格式）。增量渲染的大小，结构和容量都会影响传输，呈现和操作表示媒体类型时遇到的延迟，因此会显着影响系统性能。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTML是媒体类型的一个示例，在大多数情况下，它具有良好的延迟特性。早期HTML中的信息可以在收到时呈现，因为所有渲染信息都是早期可用的 - 在构成HTML的一小组标记标记的标准化定义中。但是，有些方面的HTML设计不适合延迟。示例包括：在文档的HEAD中放置嵌入的元数据，导致在呈现引擎可以读取显示对用户有用的部分之前需要传输和处理的可选信息[ 93]。嵌入图像没有渲染大小提示，要求在显示周围HTML的其余部分之前接收图像的前几个字节（包含布局大小的部分）; 动态调整大小的表列，要求渲染器在开始显示顶部之前读取并确定整个表的大小; 并且，关于解析格式错误的标记语法的惰性规则，通常要求渲染引擎在确定缺少一个键标记字符之前解析整个文件。\n\n#### 4.5.4.3 Java与JavaScript\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST还可用于深入了解为什么某些媒体类型在Web架构中的使用率高于其他媒体类型，即使开发者意见的平衡不利于他们。Java applet与JavaScript的情况就是一个例子。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java TM 是一种流行的编程语言，最初是为电视机顶盒中的应用程序开发的，但是当它被引入Web作为实现按需代码功能的手段时，它首先获得了声名狼借。尽管该语言得到了其所有者Sun Microsystems，Inc。的大量媒体支持，以及寻求替代C ++语言的软件开发人员的好评如潮，但它未能被应用程序开发人员广泛采用，以满足代码需求。在网络内。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Java推出后不久，Netscape Communications Corporation的开发人员为嵌入式按需代码创建了一种单独的语言，最初称为LiveScript，但后来因营销原因改为JavaScript名称（这两种语言除此之外几乎没有共同点）。虽然最初被嘲笑嵌入HTML并且与正确的HTML语法不兼容，但自从推出以来，JavaScript的使用率一直在稳步增长。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问题是：为什么JavaScript在Web上比Java更成功？它当然不是因为它的技术质量作为一种语言，因为与Java相比，它的语法和执行环境都被认为是差的。这也不是因为市场营销：Sun在这方面远远超过Netscape，并且还在继续这样做。这并不是因为语言的任何固有特性，因为Java在所有其他编程领域（独立应用程序，servlet等）中比JavaScript更成功。为了更好地理解这种差异的原因，我们需要根据其特性评估Java作为REST中的表示媒体类型。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;JavaScript更适合Web技术的部署模型。它的入门门槛要低得多，无论是作为一种语言的整体复杂性还是新手程序员整理第一段工作代码所需的初始工作量。JavaScript对交互的可见性影响也较小。独立组织可以像复制HTML一样阅读，验证和复制JavaScript源代码。相反，Java是作为二进制打包存档下载的 - 因此用户可以信任Java执行环境中的安全限制。同样，Java还有许多在安全环境中被认为有问题的功能，包括将RMI请求发送回原始服务器的能力。RMI不支持中介机构的可见性。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然而，两者之间最重要的区别可能是JavaScript导致较少的用户感知延迟。JavaScript通常作为主要表示的一部分下载，而Java applet则需要单独的请求。Java代码一旦转换为字节代码格式，就比典型的JavaScript大得多。最后，虽然可以在下载HTML页面的其余部分时执行JavaScript，但Java要求在应用程序开始之前下载并安装完整的类文件包。因此，Java不支持增量渲染。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一旦语言的特征与REST约束背后的基本原理相同，就可以更容易地根据现代Web架构中的行为来评估技术。\n\n# 5 总结\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST是一组协调的体系结构约束，旨在最大限度地减少延迟和网络通信，同时最大限度地提高组件实现的独立性和可伸缩性。这是通过在连接器语义上设置约束来实现的，其中其他样式专注于组件语义。REST支持交互的缓存和重用，组件的动态可替代性以及中介处理操作，从而满足Internet规模分布式超媒体系统的需求。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现代Web是REST风格体系结构的一个实例。虽然基于Web的应用程序可以包括对其他交互方式的访问，但其协议和性能问题的核心焦点是分布式超媒体。REST仅详细说明了体系结构中那些被认为对于Internet规模的分布式超媒体交互至关重要的部分。可以看到Web体系结构的改进领域，其中现有协议无法表达组件交互的所有潜在语义，并且可以在不改变体系结构功能的情况下用更有效的表单替换语法的细节。同样，可以将建议的扩展与REST进行比较，以确定它们是否适合架构。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在理想的世界中，软件系统的实现与其设计完全匹配。现代Web体系结构的某些功能确实与REST中的设计标准完全对应，例如使用URI作为资源标识符以及使用Internet媒体类型来标识表示数据格式。然而，现代Web协议的某些方面尽管存在架构设计，但由于遗留实验失败（但必须保留以便向后兼容）和开发人员在不知道架构风格的情况下部署的扩展。REST提供的模型不仅用于开发和评估新功能，还用于识别和理解损坏的功能。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;万维网可以说是世界上最大的分布式应用程序。了解Web底层的关键架构原则可以帮助解释其技术成功，并可能导致其他分布式应用程序的改进，特别是那些适合相同或类似交互方法的应用程序。REST有助于提供现代Web软件体系结构背后的基本原理，以及如何在设计和评估真实软件系统时系统地应用软件工程原理的重要教训。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于基于网络的应用程序，系统性能主要由网络通信决定。对于分布式超媒体系统，组件交互包括大粒度数据传输而不是计算密集型任务。REST风格是为满足这些需求而开发的。它专注于资源和表示的通用连接器接口，实现了组件的中间处理，缓存和可替代性，这反过来又允许基于Web的应用程序从1994年的100,000个请求扩展到1999年的600,000,000个请求。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;REST体系结构样式已通过HTTP / 1.0 和HTTP / 1.1标准的六年开发，URI和相对URL标准的详细阐述以及几十个成功部署的验证在现代Web架构中独立开发的商业级软件系统。它既是设计指导的模型，也是Web协议架构扩展的酸性测试。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;未来的工作将侧重于将架构指南扩展到开发HTTP / 1.x协议系列的替代品，使用更高效的标记化语法，但不会丢失REST标识的理想属性。无线设备的需求与REST背后的原理具有许多共同特征，将促进应用程序级协议设计和涉及活动中介的体系结构的进一步增强。还有一些兴趣是扩展REST以考虑可变请求优先级，差异化服务质量以及由连续数据流组成的表示，例如由广播音频和视频源生成的数据流。\n# 参考\n[1]Roy Thomas Fielding,Architectural Styles and the Design of Network-based Software Architectures[D], CALIFORNIA,UNIVERSITY OF CALIFORNIA，2000  \n**文章链接**：https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm\n\n\n\n\n\n\n\n","tags":["软件架构"]},{"title":"python各种web框架对比","url":"/2018/07/17/python各种web框架对比/","content":"# 0 引言\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;python在web开发方面有着广泛的应用。鉴于各种各样的框架，对于开发者来说如何选择将成为一个问题。为此，我特此对比较常见的几种框架从性能、使用感受以及应用情况进行一个粗略的分析。\n\n# 1 Django\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Django是一个开放源代码的Web应用框架，由Python写成。采用了MTV的框架模式，即模型M，模板T和视图V。它最初是被开发来用于管理劳伦斯出版集团旗下的一些以新闻内容为主的网站的，即是CMS（内容管理系统）软件。Django与其他框架比较，它有个比较独特的特性，支持orm，将数据库的操作封装成为python，对于需要适用多种数据库的应用来说是个比较好的特性。不过这种特性，已经有其他库完成了，sqlalchemy.\n\n# 2 Flask\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Flask是一个使用 Python 编写的轻量级 Web 应用框架。其 WSGI 工具箱采用 Werkzeug ，模板引擎则使用 Jinja2 。Flask使用 BSD 授权。  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Flask也被称为 “microframework” ，因为它使用简单的核心，用 extension 增加其他功能。Flask没有默认使用的数据库、窗体验证工具。  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Flask 很轻，花很少的成本就能够开发一个简单的网站。非常适合初学者学习。Flask 框架学会以后，可以考虑学习插件的使用。例如使用 WTForm + Flask-WTForm 来验证表单数据，用 SQLAlchemy + Flask-SQLAlchemy 来对你的数据库进行控制。\n\n# 3 Tornado\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tornado是一种 Web 服务器软件的开源版本。Tornado 和现在的主流 Web 服务器框架（包括大多数 Python 的框架）有着明显的区别：它是非阻塞式服务器，而且速度相当快。  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;得利于其 非阻塞的方式和对epoll的运用，Tornado 每秒可以处理数以千计的连接，因此 Tornado 是实时 Web 服务的一个 理想框架。不过现在与众多的框架比较，Tornado已经被抛在了后面，Django已经超过了它，更不说其他框架了，只能说Tornado使用纯python开发的性能还是不能与其他框架借助于cython开发的性能。\n\n# 4 web.py\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;web.py 是一个Python 的web 框架，它简单而且功能强大。web.py 是公开的，无论用于什么用途都是没有限制的。而且相当的小巧，应当归属于轻量级的web 框架。但这并不影响web.py 的强大，而且使用起来很简单、很直接。在实际应用上，web.py 更多的是学术上的价值，因为你可以看到更多web 应用的底层，这在当今“抽象得很好”的web 框架上是学不到的 ：）\n\n# 5 Aiohttp\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;高性能异步web框架，既有客户端的也有服务端的，还支持web-socket\n# 6 Sanic\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与flask类似，并支持异步\n# 7 Vibora\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;旨在成为最快的python web框架。vibora的高性能依赖于 cython实现的uvloop异步框架及cython实现的http_parser, 再加上一些cython构建的web组件，比如 模板，user-route等。目前还处于测试阶段。\n\n# 8 Bottle\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bottle是一个简单高效的遵循WSGI的微型python Web框架。说微型，是因为它只有一个文件，除Python标准库外，它不依赖于任何第三方模块。\n\n# 9 Falcon\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Falcon是一个构建云API的高性能Python框架，它鼓励使用REST架构风格，尽可能以最少的力气做最多的事情。\n\n# 10 weppy\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;性能优于flask的一个全栈web框架\n\n# 11 并发请求对比\n框架 | 请求量/秒 | 版本\n---|---|---\nTornado | 14197 | 5.0.2\nDjango | 22823 | 2.0.6\nFlask | 37487 | 1.0.2\nAiohttp | 61252 | 3.3.2\nSanic | 119764 | 0.7.0\nVibora | 368456 | 0.0.6\n\n# 参考\n1. https://github.com/vibora-io/vibora\n2. https://pypi.org/project/aiohttp/\n3. https://www.colabug.com/3416265.html","tags":["web"]},{"title":"TensorFlow","url":"/2018/06/21/TensorFlow/","content":"# 0 引言\n自从去年AlphaGo打败中国围棋高手柯洁以来，人工智能就在社会上被炒的沸沸扬扬。人们对人工智能充满了无限的期待，与人工智能的相关项目都变得炙手可热，学习人工智能更是成为了社会热潮。其实，人工智能的概念早在上世纪30年代就已经被图灵提及，图灵也被称为人工智能之父。人工智能的发展也颇为曲折，在这近80年的时间里，它的起起伏伏总让人们对人工智能充满了疑惑。究竟机器是否能够达到所谓的人工智能？如果真有类似于人类的智能机器，它对社会伦理将会构成威胁！但是人类存在的意义就是探索未知，突破自身局限，将不可能变为可能。所以在疑惑和担心中，人们一次又一次推着人工智能向前发展。这次人工智能出现如此大的突破，主要归结于以下几个原因：  \n\n1.  计算能力有了大幅提升\n2. 深度学习技术有了巨大的提升\n3. 像谷歌这样的科技公司做了很多的人工智能基础工作，比如TensorFlow的开源  \n\n从以上几个原因中我们发现，人工智能基础技术的开源为人工智能业界打开了一片新天地。人工智能也从科研院所走进各行各业对此有兴趣的人群中。独乐乐不如众乐乐，众人拾柴火焰高，个人智慧总是无法与集体智慧相比。我相信TensorFlow的开源会极大地促进人工智能的发展。我们无法判断我们的未来，因此我们只有不断地探索。\n\n# 1 什么是TensorFlow\nTensorFlow™ 是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。节点（Nodes）在图中表示数学操作，图中的线（edges）则表示在节点间相互联系的多维数据数组，即张量（tensor）。它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。TensorFlow 最初由Google大脑小组（隶属于Google机器智能研究机构）的研究员和工程师们开发出来，用于机器学习和深度神经网络方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域。\n\n# 2 TensorFlow的特征\n\n\n-  __高度的灵活性__ ：TensorFlow 不是一个严格的“神经网络”库。只要你可以将你的计算表示为一个数据流图，你就可以使用Tensorflow。你来构建图，描写驱动计算的内部循环。我们提供了有用的工具来帮助你组装“子图”（常用于神经网络），当然用户也可以自己在Tensorflow基础上写自己的“上层库”。定义顺手好用的新复合操作和写一个python函数一样容易，而且也不用担心性能损耗。当然万一你发现找不到想要的底层数据操作，你也可以自己写一点c++代码来丰富底层的操作。\n-  __真正的可移植性（Portability）__ ：Tensorflow 在CPU和GPU上运行，比如说可以运行在台式机、服务器、手机移动设备等等。想要在没有特殊硬件的前提下，在你的笔记本上跑一下机器学习的新想法？Tensorflow可以办到这点。准备将你的训练模型在多个CPU上规模化运算，又不想修改代码？Tensorflow可以办到这点。想要将你的训练好的模型作为产品的一部分用到手机app里？Tensorflow可以办到这点。你改变主意了，想要将你的模型作为云端服务运行在自己的服务器上，或者运行在Docker容器里？Tensorfow也能办到。Tensorflow就是这么拽 :)\n-  __将科研和产品联系在一起__ ：过去如果要将科研中的机器学习想法用到产品中，需要大量的代码重写工作。那样的日子一去不复返了！在Google，科学家用Tensorflow尝试新的算法，产品团队则用Tensorflow来训练和使用计算模型，并直接提供给在线用户。使用Tensorflow可以让应用型研究者将想法迅速运用到产品中，也可以让学术性研究者更直接地彼此分享代码，从而提高科研产出率。\n-  __自动求微分__ ：基于梯度的机器学习算法会受益于Tensorflow自动求微分的能力。作为Tensorflow用户，你只需要定义预测模型的结构，将这个结构和目标函数（objective function）结合在一起，并添加数据，Tensorflow将自动为你计算相关的微分导数。计算某个变量相对于其他变量的导数仅仅是通过扩展你的图来完成的，所以你能一直清楚看到究竟在发生什么。\n-  __多语言支持__ ：Tensorflow 有一个合理的c++使用界面，也有一个易用的python使用界面来构建和执行你的graphs。你可以直接写python/c++程序，也可以用交互式的ipython界面来用Tensorflow尝试些想法，它可以帮你将笔记、代码、可视化等有条理地归置好。当然这仅仅是个起点——我们希望能鼓励你创造自己最喜欢的语言界面，比如Go，Java，Lua，Javascript，或者是R。\n-  __性能最优化__ ：比如说你又一个32个CPU内核、4个GPU显卡的工作站，想要将你工作站的计算潜能全发挥出来？由于Tensorflow 给予了线程、队列、异步操作等以最佳的支持，Tensorflow 让你可以将你手边硬件的计算潜能全部发挥出来。你可以自由地将Tensorflow图中的计算元素分配到不同设备上，Tensorflow可以帮你管理好这些不同副本。\n\n# 3 基于TensorFlow的应用\n- AlphaGo\n- 自动驾驶\n- 天文学寻找类似地球的行星\n- 荷兰的养殖场监测奶牛的行为和身体数据，使用 TensorFlow 来分析奶牛健康状况\n- 巴西亚马逊丛林的护林人员，使用 TensorFlow 来识别丛林中的声音，来判断是否有盗伐者\n- 在非洲，开发者使用 TensorFlow 制作出判断植物是否生病的手机应用，只要对植物进行拍照，就能进行鉴定\n- Google 开源了基于 TensorFlow 的 Magenta 项目，一个功能是能够自动生成音乐，你输入一个音符，程序能够建议下一个音符\n- 在艺术和文化领域，你可以拍一个照片，程序能找出和你相似的艺术照片\n- 谷歌翻译可以在没有联网的情况下实时进行翻译。有这样一个上面印有“Milk”的包装盒，你只要打开谷歌翻译并用手机对准它，谷歌翻译就能自动识别文字，自动翻译出“牛奶”，并把翻译的结果贴在原来这个照片上\n- Google 的大量产品使用了 TensorFlow。比如在语音方面，包括语言的识别和合成，像 DeepMind 发布的语音合成算法 WaveNet，合成的效果非常好。对人机对话，Google I/O 发布了 AI 打电话预定的 Demo，叫做 Google Duplex\n- 在视觉方面，Google Photos 能自动把所有照片做分析，识别里面的人和物体，自动得到一些标签，你可以直接搜索这些照片，不再需要手动加标签。还有 Google 的 Pixel 系列手机，拍照模式中，自动把前景突出一些，背景模糊化处理\n- 在机器人领域，可以使用 TensorFlow 让四脚机器人学习如何站立和平衡\n- 使用 TensorFlow 来帮助 Google 数据中心做能耗优化\n# 参考\n1. http://www.tensorfly.cn/\n2. https://blog.csdn.net/jILRvRTrc/article/details/80578131\n\n\n","tags":["谷歌"]},{"title":"神经网络算法","url":"/2018/06/19/神经网络算法/","content":"\n# 一、 引言\n\n深度学习带来了机器学习的革命。最近非常火的AlphaGo以及比较流行的人脸识别、语音识别、机器翻译、自动驾驶等应用都是借助于深度学习。可以说深度学习已经成为了人工智能中最核心的一项技术。在八九十年代之前，神经网络就已经出现了，不过那个时候受限于计算能力，模型的规模比较小，所以它的表现不如一些经过优化过的其他机器学习方法，这样就很难解决真实的大规模问题。\n  \n随着计算能力的增加，可以看到深度学习解决问题的精度，已经超过了其他机器学习方法。以图片识别问题为例，在 2011 年的时候，它的错误率是 26%，而人只有 5%，所以这个时候离实用有非常大的距离。到 2016 年为止，它的错误率已经减少到了 3% 左右，深度学习在该领域呈现出非常惊人的能力，这就是为什么深度学习在图像识别领域吸引了产业界的大量关注。\n\n# 二、绪论\n\n思维学普遍认为，人类大脑的思维分为抽象（逻辑）思维、形象（直观）思维和灵感（顿悟）思维三种基本方式。人工神经网络就是模拟人思维的第二种方式。这是一个非线性动力学系统，其特色在于信息的分布式存储和并行协同处理。虽然单个神经元的结构极其简单，功能有限，但大量神经元构成的网络系统所能实现的行为却是极其丰富多彩的。\n  \n逻辑性的思维是指根据逻辑规则进行推理的过程。它先将信息化成概念，并用符号表示，然后，根据符号运算按串行模式进行逻辑推理。\n\n这一过程可以写成串行的指令，让计算机执行。然而，直观性的思维是将分布式存储的信息综合起来，结果是忽然间产生的想法或解决问题的办法。\n  \n这种思维方式的根本之点在于以下两点：1.信息是通过神经元上的兴奋模式分布储在网络上；2.信息处理是通过神经元之间同时相互作用的动态过程来完成的。\n\n# 三、概念\n\n神经网络是一门重要的机器学习技术。它是目前最为火热的研究方向--深度学习的基础。学习神经网络不仅可以让你掌握一门强大的机器学习方法，同时也可以更好地帮助你理解深度学习技术。\n    \n神经网络是一种模拟人脑的神经网络以期能够实现类人工智能的机器学习技术。人脑中的神经网络是一个非常复杂的组织。成人的大脑中估计有1000亿个神经元之多。神经元模型是一个包含输入，输出与计算功能的模型。输入可以类比为神经元的树突，而输出可以类比为神经元的轴突，计算则可以类比为细胞核。\n  \n<br/> __神经元__ \n![图片描述](/images/sjy.jpg)  \n<br/>\n下图是一个典型的神经元模型：包含有3个输入，1个输出，以及2个计算功能。连接是神经元中最重要的东西。每一个连接上都有一个权重。一个神经网络的训练算法就是让权重的值调整到最佳，以使得整个网络的预测效果最好。我们使用a来表示输入，用w来表示权值。一个表示连接的有向箭头可以这样理解：在初端，传递的信号大小仍然是a，端中间有加权参数w，经过这个加权后的信号会变成a*w，因此在连接的末端，信号的大小就变成了a*w。\n\n<br/> __神经元模型__ <br/>\n\n![图片描述](/images/sjymx.jpg)\n\n神经网络分为单层神经网络（感知器）、双层神经网络（多层感知器）、多层神经网络（深度学习）。  \n\n# 四、单层神经网络\n\n拥有一个计算层的神经网络被称作单层神经网络。\n  \n1958年，计算科学家Rosenblatt提出了由两层神经元组成的神经网络。他给它起了一个名字--“感知器”（Perceptron）（有的文献翻译成“感知机”，下文统一用“感知器”来指代）。\n感知器只能做简单的线性分类任务。\n  \n<br/> __单层神经网络模型__   \n<br/>\n\n\n![图片描述](/images/dcsjwl.jpg)\n\n\n\n# 五、两层神经网络\n\n两层神经网络除了拥有一个输入层、输出层以外，还增加了中间层。中间层和输出层都是计算层。\n  \nMinsky说过单层神经网络无法解决异或问题。但是当增加一个计算层以后，两层神经网络不仅可以解决异或问题，而且具有非常好的非线性分类效果。不过两层神经网络的计算是一个问题，没有一个较好的解法。\n  \n1986年，Rumelhar和Hinton等人提出了反向传播（Backpropagation，BP）算法，解决了两层神经网络所需要的复杂计算量问题，从而带动了业界使用两层神经网络研究的热潮。目前，大量的教授神经网络的教材，都是重点介绍两层（带一个隐藏层）神经网络的内容。\n   \n两层神经网络除了包含一个输入层，一个输出层以外，还增加了一个中间层。此时，中间层和输出层都是计算层。我们扩展上节的单层神经网络，在右边新加一个层次（只含有一个节点）。\n  \n<br/> __双层神经网络模型__  \n<br/>\n\n![图片描述](/images/scsjwl.jpg)\n<br/>  \n\n与单层神经网络不同。理论证明，两层神经网络可以无限逼近任意连续函数。\n  \n但是神经网络仍然存在若干的问题：尽管使用了BP算法，一次神经网络的训练仍然耗时太久，而且困扰训练优化的一个问题就是局部最优解问题，这使得神经网络的优化较为困难。同时，隐藏层的节点数需要调参，这使得使用不太方便，工程和研究人员对此多有抱怨。\n\n# 六、多层神经网络（深度学习）\n\n2006年，Hinton在《Science》和相关期刊上发表了论文，首次提出了“深度信念网络”的概念。与传统的训练方式不同，“深度信念网络”有一个“预训练”（pre-training）的过程，这可以方便的让神经网络中的权值找到一个接近最优解的值，之后再使用“微调”(fine-tuning)技术来对整个网络进行优化训练。这两个技术的运用大幅度减少了训练多层神经网络的时间。他给多层神经网络相关的学习方法赋予了一个新名词--“深度学习”。\n    \n与两层层神经网络不同。多层神经网络中的层数增加了很多。增加更多的层次有什么好处？更深入的表示特征，以及更强的函数模拟能力。更深入的表示特征可以这样理解，随着网络的层数增加，每一层对于前一层次的抽象表示更深入。在神经网络中，每一层神经元学习到的是前一层神经元值的更抽象的表示。例如第一个隐藏层学习到的是“边缘”的特征，第二个隐藏层学习到的是由“边缘”组成的“形状”的特征，第三个隐藏层学习到的是由“形状”组成的“图案”的特征，最后的隐藏层学习到的是由“图案”组成的“目标”的特征。通过抽取更抽象的特征来对事物进行区分，从而获得更好的区分与分类能力。\n  \n<br/>\n __多层神经网络模型__  \n    \n<br/>\n\n![图片描述](/images/mcsjwl.jpg)\n<br/>\n\n目前，深度神经网络在人工智能界占据统治地位。但凡有关人工智能的产业报道，必然离不开深度学习。神经网络界当下的四位引领者除了前文所说的Ng，Hinton以外，还有CNN的发明人Yann Lecun，以及《Deep Learning》的作者Bengio。  \n\n前段时间一直对人工智能持谨慎态度的马斯克，搞了一个OpenAI项目，邀请Bengio作为高级顾问。马斯克认为，人工智能技术不应该掌握在大公司如Google，Facebook的手里，更应该作为一种开放技术，让所有人都可以参与研究。马斯克的这种精神值得让人敬佩。   \n\n多层神经网络的研究仍在进行中。现在最为火热的研究技术包括RNN，LSTM等，研究方向则是图像理解方面。图像理解技术是给计算机一幅图片，让它用语言来表达这幅图片的意思。ImageNet竞赛也在不断召开，有更多的方法涌现出来，刷新以往的正确率。\n\n# 七、 总结\n\n神经网络的发展历史曲折荡漾，既有被人捧上天的时刻，也有摔落在街头无人问津的时段，中间经历了数次大起大落。从单层神经网络（感知器）开始，到包含一个隐藏层的两层神经网络，再到多层的深度神经网络，一共有三次兴起过程。\n  \n如果把1949年Hebb模型提出到1958年的感知机诞生这个10年视为落下（没有兴起）的话，那么神经网络算是经历了“三起三落”这样一个过程，跟“小平”同志类似。俗话说，天将降大任于斯人也，必先苦其心志，劳其筋骨。经历过如此多波折的神经网络能够在现阶段取得成功也可以被看做是磨砺的积累吧。\n  \n历史最大的好处是可以给现在做参考。科学的研究呈现螺旋形上升的过程，不可能一帆风顺。同时，这也给现在过分热衷深度学习与人工智能的人敲响警钟，因为这不是第一次人们因为神经网络而疯狂了。1958年到1969年，以及1985年到1995，这两个十年间人们对于神经网络以及人工智能的期待并不现在低，可结果如何大家也能看的很清楚。\n  \n因此，冷静才是对待目前深度学习热潮的最好办法。如果因为深度学习火热，或者可以有“钱景”就一窝蜂的涌入，那么最终的受害人只能是自己。神经网络界已经两次有被人们捧上天了的境况，相信也对于捧得越高，摔得越惨这句话深有体会。因此，神经网络界的学者也必须给这股热潮浇上一盆水，不要让媒体以及投资家们过分的高看这门技术。很有可能，三十年河东，三十年河西，在几年后，神经网络就再次陷入谷底。根据上图的历史曲线图，这是很有可能的。  \n\n# 八、展望\n\n根据一些最近的研究发现，人脑内部进行的计算可能是类似于量子计算形态的东西。而且目前已知的最大神经网络跟人脑的神经元数量相比，仍然显得非常小，仅不及1%左右。所以未来真正想实现人脑神经网络的模拟，可能需要借助量子计算的强大计算能力。\n\n# 参考\n1. https://www.cnblogs.com/subconscious/p/5058741.html#eighth\n2. https://blog.csdn.net/jILRvRTrc/article/details/80578131\n3. https://baike.baidu.com/item/神经网络算法/1252235?fr=aladdin","tags":["算法"]},{"title":"HBase的Region分区","url":"/2018/06/12/HBase的Region分区/","content":"\n# 1 Region概念\nRegion是表获取和分布的基本元素，由每个列族的一个Store组成。对象层级如下所示：\nTable -> Region -> Store -> MemStore | StoreFile -> Block\n\n\n1. Store：Store per ColumnFamily for each Region for the table\n2. MemStore：MemStore for each Store for each Region for the table\n3. StoreFile：StoreFiles for each Store for each Region for the table\n4. Block：Blocks within a StoreFile within a Store for each Region for the table\n\nRegion的大小是一个棘手的问题，需要考量如下几个因素：  \n\n1. Region是HBase中分布式存储和负载均衡的最小单元。不同Region分布到不同RegionServer上，但并不是存储的最小单元\n2. Region由一个或者多个Store组成，每个store保存一个columns family，每个Strore又由一个memStore和0至多个StoreFile 组成。memStore存储在内存中， StoreFile存储在HDFS上\n3. HBase通过将region切分在许多机器上实现分布式。也就是说，你如果有16GB的数据，只分了2个region， 你却有20台机器，有18台就浪费了\n4. region数目太多就会造成性能下降，现在比以前好多了。但是对于同样大小的数据，700个region比3000个要好\n5. region数目太少就会妨碍可扩展性，降低并行能力。有的时候导致压力不够分散。这就是为什么，你向一个10节点的HBase集群导入200MB的数据，大部分的节点是idle的\n6. RegionServer中1个region和10个region索引需要的内存量没有太多的差别\n\n当region中的StoreFile大小超过了上面配置的值的时候，该region就会被拆分，具体的拆分策略见下文。\n\n# 2 Region 拆分策略\nRegion的分割操作是不可见的，因为Master不会参与其中。RegionServer拆分region的步骤是，先将该region下线，然后拆分，将其子region加入到META元信息中，再将他们加入到原本的RegionServer中，最后汇报Master。\n\n# 3 参考\nhttps://www.cnblogs.com/duanxz/p/3154487.html\n\n\n","tags":["Region"]},{"title":"InfluxDB","url":"/2018/06/12/InfluxDB/","content":"\n# 1 概览\nInfluxDB是一个开源分布式时序、事件和指标数据库。使用go语言编写，无需外部依赖。其设计目标是实现分布式和水平伸缩扩展。  \n它有三大特性：  \n\n1. Time Series （时间序列）：你可以使用与时间有关的相关函数（如最大，最小，求和等  \n2. Metrics（度量）：你可以实时对大量数据进行计算  \n3. Eevents（事件）：它支持任意的事件数据  \n\n# 2 特点  \n\n- schemaless(无结构)，可以是任意数量的列  \n- scalable（可扩展 ）\n- min, max, sum, count, mean, median 一系列函数，方便统计  \n- Native HTTP API, 内置http支持，使用http读写  \n- Powerful Query Language 类似sql  \n- Built-in Explorer 自带管理工具  \n\n# 3 API\n\nInfluxDB 支持两种api方式：\n\n- Http API\n- Protobuf API\n\n# 4 查询语言  \n\n\nInfluxDB 提供了类似sql的查询语言：\n\n``` \n    select * from events where state == 'NY';\n    \n    select * from log_lines where line =~ /error/i;\n    \n    select * from events where customer_id == 23 and type == 'click';\n    \n    select * from response_times where value > 500;\n    \n    select * from events where email !~ /.*gmail.*/;\n    \n    select * from nagios_checks where status != 0;\n    \n    select * from events \n    where (email =~ /.*gmail.* or email =~ /.*yahoo.*/) and state == 'ny';\n    \n    delete from response_times where time > now() - 1h    \n```\n\n\n非常容易上手, 还支持Group By, Merging Series, Joining Series， 并内置常用统计函数，比如max, min, mean 等\n\n# 5 库  \n\n常用语言的库都有，因为api简单，也很容易自己封装。\n\nInfluxdDB作为很多监控软件的后端，这样监控数据就可以直接存储在InfluxDB。比如：StatsD, CollectD, FluentD。\n\n还有其它的可视化工具支持InfluxDB, 这样就可以基于InfluxDB很方便的搭建监控平台\n\n# 6 InfluxDB 数据可视化工具  \n\nInfluxDB 用于存储基于时间的数据，比如监控数据，因为InfluxDB本身提供了Http API，所以可以使用InfluxDB很方便的搭建了个监控数据存储中心。\n\n对于InfluxDB中的数据展示，官方admin有非常简单的图表, 看起来是这样的:\n\n\n![](/images/influxdb-2.jpg)\n\n除了自己写程序展示数据还可以选择：\n\n- tasseo https://github.com/obfuscurity/tasseo/  \n- grafana https://github.com/torkelo/grafana  \n\n## 6.1 tasseo  \n\ntasseo,为Graphite写的Live dashboard，现在也支持InfluxDB,tasseo 比较简单, 可以配置的选项很少。\n\n\n![](/images/influxdb-3.png)\n\n## 6.2 Grafana  \n\nGrafana是一个纯粹的html/js应用，访问InfluxDB时不会有跨域访问的限制。只要配置好数据源为InfluxDB之后就可以，剩下的工作就是配置图表。Grafana 功能非常强大。使用ElasticsSearch保存DashBoard的定义文件，也可以Export出JSON文件(Save ->Advanced->Export Schema)，然后上传回它的/app/dashboards目录。 \n\n配置数据源:\n\n```\n     datasources: {      \n          influx: {\n            default: true,\n            type: 'influxdb',\n            url: 'http://<your_influx_db_server>:8086/db/<db_name>',\n            username: 'test',\n            password: 'test',\n          }\n        },        \n```\n\n\n最后可以看到如下图所示界面：\n\n![](/images/influxdb-4.png)\n\n# 7 与SQL数据库比较\n## 7.1 总体\nInfluxDB被设计用来处理时序数据，而SQL数据库可以处理时序数据但并不是它的主要目的。InfluxDB还有一个区别于SQL数据库的地方就是它可以存储大规模的时序数据，并且快速地对其进行实时分析。\n\n## 7.2 时序就是一切\nInfluxDB中时间戳是标识任何数据队列中数据的唯一性的标志，这与SQL数据库中，主键唯一标识一行数据一样。\n\n## 7.3 术语对比\n在InfluxDB中你不用事先定义一张表，你可以随时增加一个表的字段。InfluxDB中表被称作measurement，索引被称作tag，没有索引的字段称作field，行被称作points。InfluxDB不支持join操作。InfluxDB中的时间戳必须是Unix时间戳（GMT）或者格式化为RFC3339的有效时间字符串。\n\n## 7.4 InfluxSQL vs SQL\n\nInfluxSQL 是一种类似于SQL的语言，除了不支持Join以外，其他大部分都支持，包括支持正则表达式、支持GROUP BY、支持MAX、支持COUNT等函数。\n\n# 8 参考\n1. http://www.ttlsa.com/monitor-safe/monitor/distributed-time-series-database-influxdb/\n2. https://docs.influxdata.com/influxdb/v1.5/concepts/crosswalk/\n\n\n\n\n","tags":["go"]},{"title":"MongoDB与HBase比较","url":"/2018/06/12/MongoDB与HBase比较/","content":"\n# 一、概览\nMongoDB与HBase都是技术领先的非关系性数据库。MongoDB使用C++编写，HBase使用Java编写，HBase会受Java GC暂停的影响。MongoDB将数据存储为BSON（JSON的二进制形式表示）的文档。HBase专为 具有随机读取和写入访问模式Key-Value工作负载设计。\n\n# 二、关键概念\n许多关系数据库概念与MongoDB和HBase有相似之处。该表概述了每个系统中的一些常见概念。  \n\n|RDBMS|MongoDB|Hbase|\n|---|---|---|  \n| 表| collection|表 |\n| 行| Document| 列族|\n| 没有类似的| 分片|分区 |\n| GROUP BY| Aggregation Pipeline| MapReduce|\n| 多记录的ACID事务|多记录的ACID事务 | 没有|\n\n# 特性\n## 开发者关注特性  \n\n| MongoDB|HBase|\n|---|---|\n| __数据模型__  |Document |宽列 |\n| __支持的数据类型__ |多种|数据转化为二进制|\n|  __查询模型__ | 多功能的查询|Key-Value |\n|  __二级索引__ |支持 |需要开发人员自己解决 |\n|  __聚合__ |支持 |需要将数据移动到特定的数据分析框架中 |\n|  __文本搜索__ | 支持|需要将数据转移到的特定的数据分析框架中 |\n|  __数据保证__ | 支持| 没有|\n|  __构建响应、事件驱动应用__ | 支持| 没有|\n| __驱动支持__  |11种支持的驱动和30+社区支持 |支持Java和Thrift |\n| __事务保证__  | 支持简单的事务| 单一行原子操作|\n\n## 管理者关注特性  \n\n|  |MongoDB|HBase|  \n|--|--|--|  \n| __创建产品级集群需要的最少节点__ |3个：主节点和次节点 |10个：主和次级HMaster,RegionServers、hdfs和zookeeper |  \n|  __推荐每个节点存储的最大数据量__ |没有限制 |4TB |  \n| __主节点失效恢复时间__ |2秒，数据可在次级节点读取 |60秒，数据可在次级节点读取 |  \n|  __性能维护__ |C++编写不会出现Java GC暂停 |Java 编写，GC会出现暂停的问题|  \n| __数据分区__ | 支持hash、range、zone|仅支持hash |  \n| __备份和恢复__|||  \n|  __Spark和Hadoop适应__ |支持 |支持 |\n\n# 参考\n1. https://www.mongodb.com/compare/mongodb-hbase\n","tags":["MongoDB"]},{"title":"常见的几种开源协议","url":"/2018/06/12/常见的几种开源协议/","content":"\n# 引言\n说到开源协议，不得不提GNU。GNU is Not Unix”，这是官方给出的递归定义，永远也找不到本意，我们可以将它理解为一个自由软件工程项目或者一种计划，是由Richard Stallman在1983年9月27公开发起的，它的目标是创建一套完全自由、开放的操作系统。1985年10月Richard Stallman创立了自由软件基金会（Free Software Foundation ，FSF），其主要工作是执行GNU计划。为了保证GNU软件可以自由的“使用、复制、修改、发布”，同样也禁止部分人在GNU软件的基础上自己修改并发布的软件中添加任何限制他人自由使用的条款，在这个情况下就诞生了GNU的许可条款，再后来又产生了其他的（非GNU）许可条款，统称为开源许可协议。\n\n常见的几种开源协议如下：\n\n- GPL （GNU General Public License） ：GNU通用公共许可协议\n- LGPL （GNU Lesser General Public License） ：GNU宽通用公共许可协议\n- BSD (Berkeley Software Distribution)  :伯克利软件分发许可协议\n- MIT （Massachusetts Institute of Technology）：MIT许可协议之名源自麻省理工学院，又称“X许可协议”或“X11许可协议”\n- Apache （Apache License） ：Apache许可协议\n- MPL （Mozilla Public License） ：Mozilla公共许可协议\n\n# GPL\nGNU通用公共许可协议是一个被广泛使用的自由软件许可协议条款，GPL 保证了所有开发者的权利，同时为使用者提供了足够的复制，分发，修改的权利。\n\n- 可自由复制\n- 可自由分发\n- 可以用来盈利\n- 可自由修改\n\n# LGPL\nGNU 还有另外一种协议，叫做GNU宽通用公共协议，它对产品所保留的权利比 GPL 少，总的来说，LGPL 适合那些用于非 GPL 或非开源产品的开源类库或框架。因为GPL要求包含有部分GPL授权代码的软件以GPL方式发布，这样开发者就无法在收费的专属软件里使用GPL授权代码。 LGPL正好解决了这一问题：它不要求其它使用LGPL授权代码的软件以LGPL方式发布。注意：LGPL有一特点是LGPL软件可以被转换成GPL。这种特性对于在GPL库或应用程序中直接使用LGPL程序有一定程度之帮助。\n\n# BSD\nBSD 在软件分发方面的限制比别的开源协议（如 GNU GPL）要少。该协议有多种版本，最主要的版本有两个，新 BSD 协议与简单 BSD 协议，这两种协议经过修正，都和 GPL 兼容，并为开源组织所认可。\n\n新 BSD 协议在软件分发方面，除需要包含一份版权提示和免责声明之外，没有任何限制。另外，该协议还禁止拿开发者的名义为衍生产品背书，但简单 BSD 协议删除了这一条款。\n\n# MIT\nMIT 协议可能是几大开源协议中最宽松的一个，核心条款是：\n\n该软件及其相关文档对所有人免费，可以任意处置，包括使用，复制，修改，合并，发表，分发，再授权，或者销售。唯一的限制是，软件中必须包含上述版 权和许可提示。这意味着：\n\n- 你可以自由使用，复制，修改，可以用于自己的项目。\n- 可以免费分发或用来盈利。\n- 唯一的限制是必须包含许可声明。\n\nMIT 协议是所有开源许可中最宽松的一个，除了必须包含许可声明外，再无任何限制。\n\n# Apache\n\nApache 协议 2.0 和别的开源协议相比，除了为用户提供版权许可之外，还有专利许可，对于那些涉及专利内容的开发者而言，该协议最适合。\n\nApache 协议还有以下需要说明的地方:\n\n- 永久权利\n- 全球范围的权利\n- 授权免费，且无版税\n- 授权无排他性\n- 授权不可撤消\n\n分发代码方面包含一些要求，主要是，要在声明中对参与开发的人给予认可并包含一份许可协议原文。\n\n# MPL\nMPL既是得到自由软件基金会承认的自由软件许可证，也是得到开放源代码促进会承认的开源软件许可证。MPL允许在其授权下的源代码与其他授权的文件进行混合，包括私有许可证。但在MPL授权下的代码文件必须保持MPL授权，并且保持开源。这样的条款让MPL既不像MIT和BSD那样允许派生作品完全转化为私有，也不像GPL那样要求所有的派生作品，包括新的组件在内，全部必须保持GPL。通过允许在派生项目中存在私有模块，同时保证核心文件的开源，MPL同时激励了商业及开源社区来参与帮助开发核心软件。\n\n使用MPL授权的软件并不受专利的限制，其可以自由使用，修改，并可自由的重新发布。带有专利代码的版本仍然可以使用，转让，甚至出售，但未经许可则不能修改代码。此外，MPL并不授予用户对于开发者商标的使用权。\n\n为了满足MPL的条款限制，用户必须负担一些“责任”，主要是关于散发使用MPL授权的软件。用户必须确保重新散发的软件所有源代码均以MPL授权，即使是以可执行文件的方式提供或是与其他使用专有软件授权的源代码结合也一样。但若跟以GNU通用公共许可协议、GNU宽通用公共许可证、Affero通用公共许可证授权的源代码结合则是例外。此时开发者则可选用以上三种更加严格的条款来授权。\n\n# 参考\nhttps://blog.csdn.net/u014680729/article/details/24382261\n\n","tags":["对比"]},{"title":"avro","url":"/2018/06/12/avro/","content":"\n# 1 介绍\nAvro（[ævrə]）是Hadoop的一个子项目，由Hadoop的创始人Doug Cutting（也是Lucene，Nutch等项目的创始人）牵头开发。Avro是一个数据序列化系统，设计用于支持大批量数据交换的应用。它的主要特点有：支持二进制序列化方式，可以便捷，快速地处理大量数据；动态语言友好，Avro提供的机制使动态语言可以方便地处理Avro数据.\nAvro支持两种序列化编码方式：二进制编码和JSON编码.使用二进制编码会高效序列化，并且序列化后得到的结果会比较小；而JSON一般用于调试系统或是基于WEB的应用。对Avro数据序列化/反序列化时都需要对模式以深度优先(Depth-First)，从左到右(Left-to-Right)的遍历顺序来执行。Avro依赖模式(Schema)来实现数据结构定义。可以把模式理解为Java的类，它定义每个实例的结构，可以包含哪些属性。可以根据类来产生任意多个实例对象。对实例序列化操作时必须需要知道它的基本结构，也就需要参考类的信息。这里，根据模式产生的Avro对象类似于类的实例对象。每次序列化/反序列化时都需要知道模式的具体结构。所以，在Avro可用的一些场景下，如文件存储或是网络通信，都需要模式与数据同时存在。Avro数据以模式来读和写(文件或是网络)，并且写入的数据都不需要加入其它标识，这样序列化时速度快且结果内容少。由于程序可以直接根据模式来处理数据，所以Avro更适合于脚本语言的发挥。\n\n# 2 使用\n\n## 2.1 需要的Jar包依赖\n\navro-1.7.3.jar，avro-tools-1.7.3.jar，jackson-core-asl-1.9.3.jar，jackson-mapper-asl-1.9.3.jar  \n\n## 2.2 定义模式\n\n在avro中，它是用Json格式来定义模式的。模式可以由基础类型（null, boolean, int, long, float, double, bytes, and string）和复合类型(record, enum, array, map, union, and fixed)的数据组成。这里定义了一个简单的模式user.avsc:\n\n```\n{\n\t\"namespace\": \"com.zq.avro\",   \n\t\"type\": \"record\",    \n\t\"name\": \"User\",  \n\t \"fields\": [ \n\t\t\t{\n\t\t\t\t\"name\": \"name\",   \n\t\t\t\t\"type\": \"string\"\n\t\t\t}, \n\t\t\t{\n\t\t\t\t\"name\": \"favorite_number\", \n\t\t\t \t\"type\": [\"int\", \"null\"]\n\t\t\t}, \n\t\t\t{\n\t\t\t\t\"name\": \"favorite_color\",  \n\t\t\t\t\"type\": [\"string\", \"null\"]\n\t\t\t} \n\t] \n}\n```\n\n## 2.3 编译模式\n\nAvro可以允许我们根据模式的定义而生成相应的类，一旦我们定义好相关的类，程序中就不需要直接使用模式了。可以用avro-tools jar包根据user.avsc生成User.java，语法如下:\n\n``\njava -jar avro-tools-1.7.4.jar compile schema . [注意这里有第三个参数\".\"]\n``\n\n命令执行后会在当前目录根据设定的包结构生成一个User.java类，然后就可以将定义的User对象用avro将它序列化存放到本地文件中，再将其反序列化.\n\n \n","tags":["大数据"]},{"title":"数据序列化框架对比分析","url":"/2018/06/11/数据序列化框架对比分析/","content":"# 1 概览\n由于独立于应用系统，分布式缓存的本质就是将所有的业务数据对象序列化为字节数组，然后保存到自己的内存中。所使用的序列化方案也自然会成为影响系统性能的关键点之一。一般来说，我们对一个序列化框架的关注主要有以下几点：\n1. 序列化速度：即对一个普通对象，将其从内存对象转换为字节数组需要多长时间；这个当然是越快越好  \n2. 对象压缩比：即序列化后生成对象的与原内存对象的体积比  \n3. 支持的数据类型范围：序列化框架都支持什么样的数据结构；对于大部分的序列化框架来说，都会支持普通的对象类型，但是对于复杂对象（比如说多继承关系、交叉引用、集合类等）可能不支持或支持的不够好  \n4. 易用性：一个好的序列化框架必须也是使用方便的，不需要用户做太多的依赖或者额外配置  \n\n对于一个序列化框架来说，以上几个特性很难都做到很出色，这是一个鱼和熊掌不可兼得的东西（具体原因后面会介绍），但是终归有自己的优势和特长，需要使用者根据实际场景仔细考量。下面就针对目前主流的序列化框架：Java、Hessian、ProtoBuf、Kryo分别从速度、压缩比、支持对象类型和易用性几方面分别讨论。  \n\n# 2 压缩比对比  \n单位：字节  \n\n| __工具__ | Java | Hessian | ProtoBuf | Kryo |  \n|:---------:|:----:|:-------:|:--------:|:----:|  \n|__仅数字__ |392 | 252|59 |56 |  \n| __数字 + 字符串__|494 |351 | 161| 149|  \n\n# 3 序列化速度对比  \n单位：纳秒  \n\n|__工具__|Java|Hessian|ProtoBuf|Kryo|  \n|:---------:|:----:|:-------:|:--------:|:----:|  \n|__仅数字__ |8733|6140|1154|2010|  \n| __数字 + 字符串__|12497|7863|2978|2863|  \n\n# 4 支持对象类型与易用性对比  \n## 4.1 Java源生序列化  \nava源生序列化是JDK自带的对象序列化方式，也是我们最常用的一种；其优点是简单、方便，不需要额外的依赖而且大部分三方系统或框架都支持；目前看来，Java源生序列化的兼容性也是最好的，可支持任何实现了Serializable接口的对象（包括多继承、循环引用、集合类等等）。但随之而来不可避免的就是，其序列化的速度和生成的对象体积和其他序列化框架相比，几乎都是最差的  \n## 4.2 Hessian  \nHessian的序列化实现和Java的原生序列化很相似，只是对于序列化反序列化本身并不需要的一些元数据进行了删减；所以Hessian可以像Java的源生序列化那样，可以支持任意类型的对象；但是在存储上，Hessian并没有做相应的优化，所以其生成的对象体积相较于Java的源生序列化并没有下降太多。由于Hessian相较于Java源生序列化并没有太大的优势，所以一般情况下，如果系统中没有使用Hessian的rpc框架，则很少单独使用Hessian的序列化机制。  \n## 4.3 Google Protobuf  \nGPB最大的特点就是自己定义了一套自己数据类型，并且规定只允许用我的这套；所以在使用GPB的时候，我们不得不为它单独定义一个描述文件，或者叫schema文件，用来完成Java对象中的基本数据类型和GPB自己定义的类型之间的一个映射。不过也正是GPB对类型的自定义，也让他可以更好的针对这些类型做出存储和解析上的优化，从而避免了Java源生序列化中的诸多弱点。对于对象属性，GPB并没有直接存储属性名称，而是根据schema文件中的映射关系，只保存该属性的顺序id；而对于，GPB针对常用的几种数据类型采用了不同程度的压缩，同时属性区段之间采用特定标记进行分隔，这样可以大大减少存储所占用的空间。对于数值类型，常见的压缩方式有变长byte、分组byte、差值存储等，一般都是根据属性的使用特点来做定制化的压缩策略。GPB的另一个优点就是跨语言，支持Java、C、PHP、Python等目前比较大众的语言；其他类似的还有Facebook的Thrift，也需要描述文件的支持，同时也包含了一个rpc框架和更丰富的语言支持  \n## 4.4 Kryo  \n前面我们提到，诸如Hessian和GPB这些三方的序列化框架或多或少的都对Java原生序列化机制做出了一些改进；而对于Kryo来说，改进无疑是更彻底一些；在很多评测中，Kryo的数据都是遥遥领先的；Kryo的处理和Google Protobuf类似。但有一点需要说明的是，Kryo在做序列化时，也没有记录属性的名称，而是给每个属性分配了一个id，但是他却并没有GPB那样通过一个schema文件去做id和属性的一个映射描述，所以一旦我们修改了对象的属性信息，比如说新增了一个字段，那么Kryo进行反序列化时就可能发生属性值错乱甚至是反序列化失败的情况；而且由于Kryo没有序列化属性名称的描述信息，所以序列化/反序列化之前，需要先将要处理的类在Kryo中进行注册，这一操作在首次序列化时也会消耗一定的性能。另外需要提一下的就是目前kryo目前还只支持Java语言。  \n# 参考  \n1. https://www.cnblogs.com/siqi/p/5096317.html","tags":["数据序列化"]},{"title":"kubernetes自动扩容功能剖析","url":"/2018/06/11/kubernetes自动扩容功能剖析/","content":"# 1 概览\nkubernetes自动扩容可以根据设定的cpu利用率，来自动增加pod副本，保证每个pod的利用率均不超过设定的cpu利用率。默认的，kubernetes每隔30秒获取一次pod的cpu利用率，也就是说，当负载增加达到或者超过设定的cpu利用率，kubernetes不一定会马上增加副本，它会在它下次更新pod利用率时进行。当负载下降，同样的kubernetes又会减少增加的副本数量，但是，它也不会立即下降。一般地，这需要10-12分钟，因为kubernetes需要保证，负载下降不是这一瞬时的下降。进行扩容的部署，需要指定pod的资源请求，如果没有设定是无法进行扩容的。扩容时，获取到的cpu利用率是指所有pod的平均cpu利用率。\n\n# 2 概念解析\n## 2.1 CPU利用率\nCPU资源以cpus为单位。允许小数值。你可以用后缀m来表示mili。例如100m cpu等同于100 milicpu，意思是0.1cpu\n\n## 2.2 资源请求\n指定pod需要的资源使用，kubernetes会根据pod需求的资源量，调度到具有足够的资源请求量的节点删\n\n## 2.3 资源限制\n指定pod最大资源请求量，如果容器超出内存限制，它将结束；如果容器超出cpu限制，它将成为cpu节流的候选者\n","tags":["自动扩容"]},{"title":"高性能分布式数据缓存系统研究","url":"/2018/06/11/高性能分布式数据缓存系统研究/","content":"# 一、前言\n\n对于任何一个高并发响应系统，如何提供高效响应都是它们需要重点解决的难题。而这里面制约系统的高并发响应的瓶颈往往在于数据库的响应时间。我们知道磁盘的读写速度远远低于内存，这也是为什么数据库会成为制约系统高并发响应的瓶颈。明白这点，我们就知道要设计一套高并发响应系统，如何设计其中的数据缓存系统和利用数据缓存系统成为其中的关键。为此，我们就需要研究下当前数据缓存系统的发展现状，特别是分布式分布式高速数据缓存系统的发展现状。\n\n# 二、数据库的瓶颈\n## 2.1数据量\n\n关系型数据库的数据量是比较小的，以我们常用的MySQL为例，单表数据条数一般应该控制在2000w以内，如果业务很复杂的话，可能还要低一些。即便是对于Oracle这些大型商业数据库来讲，其能存储的数据量也很难满足一个拥有几千万甚至数亿用户的大型互联网系统。\n\n## 2.2TPS\n在实际开发中我们经常会发现，关系型数据库在TPS上的瓶颈往往会比其他瓶颈更容易暴露出来，尤其对于大型web系统，由于每天大量的并发访问，对数据库的读写性能要求非常高；而传统的关系型数据库的处理能力确实捉襟见肘；以我们常用的MySQL数据库为例，常规情况下的TPS大概只有1500左右（各种极端场景下另当别论）；下图是MySQL官方所给出的一份测试数据：\n\n\n![](/images/318497-20160103141339432-1681082715.jpg)\n\n而对于一个日均PV千万的大型网站来讲，每个PV所产生的数据库读写量可能要超出几倍，这种情况下，每天所有的数据读写请求量可能远超出关系型数据的处理能力，更别说在流量峰值的情况下了；所以我们必须要有高效的缓存手段来抵挡住大部分的数据请求！\n\n## 2.3响应时间\n正常情况下，关系型数据的响应时间是相当不错的，一般在10ms以内甚至更短，尤其是在配置得当的情况下。但是就如前面所言，我们的需求是不一般的：当拥有几亿条数据，1wTPS的时候，响应时间也要在10ms以内，这几乎是任何一款关系型数据都无法做到的。\n那么这个问题如何解决呢？最简单有效的办法当然是缓存！\n\n# 三、缓存系统选型\n\n\n## 3.1缓存的类型\n\n### 3.1.1本地缓存\n\n本地缓存可能是大家用的最多的一种缓存方式了，不管是本地内存还是磁盘，其速度快，成本低，在有些场合非常有效；但是对于web系统的集群负载均衡结构来说，本地缓存使用起来就比较受限制，因为当数据库数据发生变化时，你没有一个简单有效的方法去更新本地缓存；然而，你如果在不同的服务器之间去同步本地缓存信息，由于缓存的低时效性和高访问量的影响，其成本和性能恐怕都是难以接受的。\n\n### 3.1.2分布式缓存\n\n本地缓存的使用很容易让你的应用服务器带上“状态”，这种情况下，数据同步的开销会比较大；尤其是在集群环境中更是如此！\n\n分布式缓存这种东西存在的目的就是为了提供比RDB更高的TPS和扩展性，同时有帮你承担了数据同步的痛苦；优秀的分布式缓存系统有大家所熟知的Memcached、Redis（当然也许你把它看成是NoSQL，但是我个人更愿意把分布式缓存也看成是NoSQL），还有国内阿里自主开发的Tair等。\n\n对比关系型数据库和缓存存储，其在读和写性能上的差距可谓天壤之别；memcached单节点已经可以做到15w以上的tps、Redis、google的levelDB也有不菲的性能，而实现大规模集群后，性能可能会更高！所以，在技术和业务都可以接受的情况下，我们可以尽量把读写压力从数据库转移到缓存上，以保护看似强大，其实却很脆弱的关系型数据库。\n\n### 3.1.3数据库缓存\n主要指数据库的查询缓存，大部分数据库都是会提供，每种数据库的具体实现细节也会有所差异，不过基本的原理就是用查询语句的hash值做key，对结果集进行缓存；如果利用的好，可以很大的提高数据库的查询效率！\n\n## 3.2选型指标\n### 3.2.1容量\n\n容量当然是越大越好了。每个系统在初期规划的时候，都会大致计算一下所要消耗的缓存空间，这主要取决于你要缓存的对象数量和单个对象的大小。一般来说，你可以采用对象属性在内存中的存储长度简单加和的方法来计算单个对象的体积，再乘以缓存对象的数量和预期增长（当然，这里边有一个热点数据的问题，这里就不细讨论了），大概得出需要使用的缓存空间；之后就可以按照这个指标去申请缓存空间或搭建缓存系统了。\n\n### 3.2.2并发量\n\n其实这里的并发量改为QPS更为贴切，因为我们的缓存不是直接面向用户的，而是面向应用的。所以我们关心的是一个缓存系统平均每秒能够承受多少的访问量。\n\n我们之所以需要缓存系统，就是要它在关键时刻能抗住我们的数据访问量的；所以，缓存系统能够支撑的并发量是一个非常重要的指标，如果它的性能还不如关系型数据库，那我们就没有使用的必要了。\n\n对于淘宝的系统来说，我们不妨按照下边的方案来估算并发量：\nQPS = 日PV × 读写次数/PV ÷ (8 × 60 × 60)\n这里我们是按照一天8个小时来计算的，这个值基于一个互联网站点的访问规律得出的。\n在估算访问量的时候，我们不得不考虑一个峰值的问题，尤其是像淘宝、京东这样大型的电商网站，经常会因为一些大的促销活动而使PV、UV冲到平时的几倍甚至几十倍，这也正是缓存系统发挥作用的关键时刻；倍受瞩目的12306在站点优化过程中也大量的引入了缓存（内存文件系统）来提升性能。\n在计算出平均值之后，再乘以一个峰值系数，基本就可以得出你的缓存系统需要承受的最高QPS，一般情况下，这个系数定在10以内是合理的。\n\n### 3.2.3响应时间\n响应时间当然也是必要的，如果一个缓存系统慢的跟蜗牛一样，甚至直接就超时了，那和我们使用MySQL也没啥区别了。\n\n一般来说，要求一个缓存系统在1ms或2ms之内返回数据是不过分的，当然前提是你的数据不会太大；如果想更快的话，那你就有点过分了，除非你是用的本地缓存；因为一般而言，在大型IDC内部，一个TCP回环（不携带业务数据）差不多就要消耗掉0.2ms至0.5ms。\n\n大部分的缓存系统，由于是基于内存，所以响应时间都很短，但是问题一般会出现在数据量和QPS变大之后，由于内存管理策略、数据查找方式、I/O模型、业务场景等方面的差异，响应时间可能会差异很多，所以对于QPS和响应时间这两项指标，还要靠上线前充分的性能测试来进一步确认，不能只单纯的依赖官方的测试结果。  \n\n### 3.2.4使用成本\n\n优秀的系统要是能够方便部署和方便运维的，不需要高端硬件、不需要复杂的环境配置、不能有过多的依赖条件，同时还要稳定、易维护\n\n### 3.2.5扩展空间\n\n缓存系统的扩展性是指在空间不足的性情况，能够通过增加机器等方式快速的在线扩容。这也是能够支撑业务系统快速发展的一个重要因素\n\n### 3.2.6容灾\n\n我们使用缓存系统的初衷就是当数据请求量很大，数据库无法承受的情况，能够通过缓存来抵挡住大部分的请求流量，所以一旦缓存服务器发生故障，而缓存系统又没有一个很好的容灾措施的话，所有或部分的请求将会直接压倒数据库上，这可能会直接导致DB崩溃。\n并不是所有的缓存系统都具有容灾特性的，所以我们在选择的时候，一定要根据自己的业务需求，对缓存数据的依赖程度来决定是否需要缓存系统的容灾特性。\n\n## 3.3常见分布式缓存系统对比\n### 3.3.1Memcached\n\nMemcached严格的说还不能算是一个分布式缓存系统，但由于Memcached的开源，其访问协议也都是公开的，所以目前有很多第三方的客户端或扩展，在一定程度上对Memcached的集群扩展做了支持，但是大部分都只是做了一个简单Hash或者一致性Hash。\n由于Memcached内部通过固定大小的chunk链的方式去管理内存数据，分配和回收效率很高，所以其读写性能也非常高。官方给出的数据，64KB对象的情况下，单机QPS可达到15w以上。\n\nMemcached集群的不同机器之间是相互独立的，没有数据方面的通信，所以也不具备failover的能力，在发生数据倾斜的时候也无法自动调整。\n\nMemcached的多语言支持非常好，目前可支持C/C++、Java、C#、PHP、Python、Perl、Ruby等常用语言，也有大量的文档和示例代码可供参考，而且其稳定性也经过了长期的检验，应该说比较适合于中小型系统和初学者使用的缓存系统。\n\n### 3.3.2Redis\nRedis被看作是Memcached的替代品。\n\nRedis除了像Memcached那样支持普通的<k,v>类型的存储外，还支持List、Set、Map等集合类型的存储，这种特性有时候在业务开发中会比较方便。\n\nRedis源生支持持久化存储，但是根据很多人的使用情况和测试结果来看，Redis的持久化性能不是很理想，官方也不推荐过度依赖Redis持久化存储功能。就性能来讲，在全部命中缓存时，Redis的性能接近memcached，但是一旦使用了持久化之后，性能会迅速下降，甚至会相差一个数量级。\n\n### 3.3.3淘宝Tair\n\nTair是淘宝自主开发并开源的一款的缓存系统，是一套真正意义上的分布式并且可以跨多机房部署，同时支持内存缓存和持久化存储的解决方案。\n\nTair实现了缓存框架和缓存存储引擎的独立，在遵守接口规范的情况下，可以根据需求更换存储引擎，目前支持mdb（基于memcached）、rdb（基于Redis）、kdb（基于kyoto cabinet，持久存储，目前已不推荐使用）和rdb（基于gooogle的levelDB，持久化存储）几种引擎\n\n由于基于mdb和rdb，所以Tair能够间距两者的特性，在并发量和响应时间上，接近二者的裸系统\n\n在扩展性和容灾方面，Tair自己做了增强；通过使用虚拟节点Hash（一致性Hash的变种实现）的方案，将key通过Hash函数映射到到某个虚拟节点（桶）上，然后通过中心服务器（configserver）来管理虚拟节点到物理节点的映射关系。这样，Tair不但实现了基于Hash的首次负载均衡，同时又可以通过调整虚拟节点和物理节点的映射关系来实现二次负载均衡，这样有效的解决了由于业务热点导致的访问不均衡问题以及线性扩容时数据迁移麻烦；此外，Tair的每台缓存服务器和中心服务器（configserver）也有主备设计，所以其可用性也大大提高。\n\n\n## 3.4缓存的设计与策略\n### 3.4.1缓存对象设计\n#### 3.4.1.1缓存对象粒度\n\n对于本地磁盘或分布是缓存系统来说，其缓存的数据一般都不是结构化的，而是半结构话或是序列化的；这就导致了我们读取缓存时，很难直接拿到程序最终想要的结果；这就像快递的包裹，如果你不打开外层的包装，你就拿不出来里边的东西.如果包裹里的东西有很多，但是其中只有一个是你需要的，其他的还要再包好送给别人；这时候你打开包裹时就会很痛苦——为了拿到自己的东西，必须要拆开包裹，但是拆开后还要很麻烦的将剩下的再包会去；等包裹传递到下一个人的手里，又是如此.\n\n所以，这个时候粒度的控制就很重要了；到底是一件东西就一个包裹呢，还是好多东西都包一块呢？前者拆起来方便，后着节约包裹数量。映射到我们的系统上，我们的缓存对象中到底要放哪些数据？一种数据一个对象，简单，读取写入都快，但是种类一多，缓存的管理成本就会很高；多种数据放在一个对象里，方便，一块全出来了，想用哪个都可以，但是如果我只要一种数据，其他的就都浪费了，网络带宽和传输延迟的消耗也很可观。\n这个时候主要的考虑点就应该是业务场景了，不同的场景使用不同的缓存粒度，折衷权衡；不要不在乎这点性能损失，缓存一般都是访问频率非常高的数据，各个点的累积效应可能是非常巨大的！\n\n当然，有些缓存系统的设计也要求我们必须考虑缓存对象的粒度问题；比如说Memcached，其chunk设计要求业务要能很好的控制其缓存对象的大小；淘宝的Tair也是，对于尺寸超过1M的对象，处理效率将大为降低.\n像Redis这种提供同时提供了Map、List结构支持的系统来说，虽然增加了缓存结构的灵活性，但最多也只能算是半结构化缓存，还无法做到像本地内存那样的灵活性。\n\n粒度设计的过粗还会遇到并发问题。一个大对象里包含的多种数据，很多地方多要用，这时如果使用的是缓存修改模式而不是过期模式，那么很可能会因为并发更新而导致数据被覆盖；版本控制是一种解决方法，但是这样会使缓存更新失败的概率大大增加，而且有些缓存系统也不提供版本支持（比如说用的很广泛的Memcached）。\n\n#### 3.4.1.2 缓存对象结构\n同缓存粒度一样，缓存的结构也是一样的道理。对于一个缓存对象来说，并不是其粒度越小，体积也越小；如果你的一个字符串就有1M大小，那也是很恐怖的.\n\n数据的结构决定着你读取的方式，举个很简单的例子，集合对象中，List和Map两种数据结构，由于其底层存储方式不同，所以使用的场景也不一样；前者更适合有序遍历，而后者适合随机存取；回想一下，你是不是曾经在程序中遇到过为了merge两个list中的数据，而不得不循环嵌套？\n\n所以，根据具体应用场景去为缓存对象设计一个更合适的存储结构，也是一个很值得注意的点。\n\n### 3.4.2 缓存更新策略\n\n缓存的更新策略主要有两种：被动失效和主动更新，下面分别进行介绍.\n\n#### 3.4.2.1 被动失效\n\n一般来说，缓存数据主要是服务读请求的，并设置一个过期时间；或者当数据库状态改变时，通过一个简单的delete操作，使数据失效掉；当下次再去读取时，如果发现数据过期了或者不存在了，那么就重新去持久层读取，然后更新到缓存中；这即是所谓的被动失效策略。\n\n但是在被动失效策略中存在一个问题，就是从缓存失效或者丢失开始直到新的数据再次被更新到缓存中的这段时间，所有的读请求都将会直接落到数据库上；而对于一个大访问量的系统来说，这有可能会带来风险。所以我们换一种策略就是，当数据库更新时，主动去同步更新缓存，这样在缓存数据的整个生命期内，就不会有空窗期，前端请求也就没有机会去亲密接触数据库。\n\n#### 3.4.2.2 主动更新\n\n前面我们提到主动更新主要是为了解决空窗期的问题，但是这同样会带来另一个问题，就是并发更新的情况.\n在集群环境下，多台应用服务器同时访问一份数据是很正常的，这样就会存在一台服务器读取并修改了缓存数据，但是还没来得及写入的情况下，另一台服务器也读取并修改旧的数据，这时候，后写入的将会覆盖前面的，从而导致数据丢失；这也是分布式系统开发中，必然会遇到的一个问题。解决的方式主要有三种：\n\n 1.__锁控制__：这种方式一般在客户端实现（在服务端加锁是另外一种情况），其基本原理就是使用读写锁，即任何进程要调用写方法时，先要获取一个排他锁，阻塞住所有的其他访问，等自己完全修改完后才能释放；如果遇到其他进程也正在修改或读取数据，那么则需要等待。锁控制虽然是一种方案，但是很少有真的这样去做的，其缺点显而易见，其并发性只存在于读操作之间，只要有写操作存在，就只能串行。\n \n 2.__版本控制__：这种方式也有两种实现，一种是单版本机制，即为每份数据保存一个版本号，当缓存数据写入时，需要传入这个版本号，然后服务端将传入的版本号和数据当前的版本号进行比对，如果大于当前版本，则成功写入，否则返回失败；这样解决方式比较简单；但是增加了高并发下客户端的写失败概率.还有一种方式就是多版本机制，即存储系统为每个数据保存多份，每份都有自己的版本号，互不冲突，然后通过一定的策略来定期合并，再或者就是交由客户端自己去选择读取哪个版本的数据。很多分布式缓存一般会使用单版本机制，而很多NoSQL则使用后者.\n\n### 3.4.3 数据对象序列化\n由于独立于应用系统，分布式缓存的本质就是将所有的业务数据对象序列化为字节数组，然后保存到自己的内存中。所使用的序列化方案也自然会成为影响系统性能的关键点之一。    \n\n一般来说，我们对一个序列化框架的关注主要有以下几点：\n\n 1.__序列化速度__：即对一个普通对象，将其从内存对象转换为字节数组需要多长时间；这个当然是越快越好\n     \n 2.__对象压缩比__：即序列化后生成对象的与原内存对象的体积比  \n \n 3.__支持的数据类型范围__：序列化框架都支持什么样的数据结构；对于大部分的序列化框架来说，都会支持普通的对象类型，但是对于复杂对象（比如说多继承关系、交叉引用、集合类等）可能不支持或支持的不够好\n     \n 4.__易用性__：一个好的序列化框架必须也是使用方便的，不需要用户做太多的依赖或者额外配置\n     \n对于一个序列化框架来说，以上几个特性很难都做到很出色，这是一个鱼和熊掌不可兼得的东西（具体原因后面会介绍），但是终归有自己的优势和特长，需要使用者根据实际场景仔细考量。序列化工具对比请参考另一篇《序列化工具对比》.\n\n# 参考\n\n\n 1. https://www.cnblogs.com/siqi/p/5096317.html\n 2. https://segmentfault.com/a/1190000003985468\n 3. https://blog.csdn.net/damacheng/article/details/42846549\n 4. https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines\n\n \n\n \n","tags":["缓存"]},{"title":"Kafka高性能吞吐揭秘","url":"/2018/06/11/Kafka高性能吞吐揭秘/","content":"# 概览\nkafka是一套分布式高性能消息缓冲集群系统，其中涉及到的名词如下所示：  \n - Topic：用于划分Message的逻辑概念，一个Topic可以分布在多个Broker上\n - Partition：是Kafka中横向扩展和一切并行化的基础，每个Topic都至少被切分为1个Partition\n - Offset：消息在Partition中的编号，编号顺序不跨Partition\n - Consumer：用于从Broker中取出/消费Message\n - Producer：用于往Broker中发送/生产Message\n - Replication：Kafka支持以Partition为单位对Message进行冗余备份，每个Partition都可以配置至少1个Replication(当仅1个Replication时即仅该Partition本身)\n - Leader：每个Replication集合中的Partition都会选出一个唯一的Leader，所有的读写请求都由Leader处理。其他Replicas从Leader处把数据更新同步到本地，过程类似大家熟悉的MySQL中的Binlog同步\n - Broker：Kafka中使用Broker来接受Producer和Consumer的请求，并把Message持久化到本地磁盘。每个Cluster当中会选举出一个Broker来担任Controller，负责处理Partition的Leader选举，协调Partition迁移等工作\n - ISR(In-Sync Replica)：是Replicas的一个子集，表示目前Alive且与Leader能够“Catch-up”的Replicas集合。由于读写都是首先落到Leader上，所以一般来说通过同步机制从Leader上拉取数据的Replica都会和Leader有一些延迟(包括了延迟时间和延迟条数两个维度)，任意一个超过阈值都会把该Replica踢出ISR。每个Partition都有它自己独立的ISR\n# Broker\n\n不同于Redis和MemcacheQ等内存消息队列，Kafka的设计是把所有的Message都要写入速度低容量大的硬盘，以此来换取更强的存储能力。实际上，Kafka使用硬盘并没有带来过多的性能损失，“规规矩矩”的抄了一条“近道”。\n  \n首先，说“规规矩矩”是因为Kafka在磁盘上只做Sequence I/O，由于消息系统读写的特殊性，这并不存在什么问题。关于磁盘I/O的性能，引用一组Kafka官方给出的测试数据(Raid-5，7200rpm):\n- Sequence I/O: 600MB/s  \n- Random I/O: 100KB/s \n\n所以通过只做Sequence I/O的限制，规避了磁盘访问速度低下对性能可能造成的影响。  \n\n那么kafka是如何抄近道的呢？首先，Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。同时如果有其他进程申请内存，回收PageCache的代价又很小，所以现代的OS都支持PageCache。使用PageCache功能同时可以避免在JVM内部缓存数据，JVM为我们提供了强大的GC能力，同时也引入了一些问题不适用与Kafka的设计。如果在Heap内管理缓存，JVM的GC线程会频繁扫描Heap空间，带来不必要的开销。如果Heap过大，执行一次Full GC对系统的可用性来说将是极大的挑战。所有在在JVM内的对象都不免带有一个Object Overhead(千万不可小视)，内存的有效空间利用率会因此降低。所有的In-Process Cache在OS中都有一份同样的PageCache。所以通过将缓存只放在PageCache，可以至少让可用缓存空间翻倍。如果Kafka重启，所有的In-Process Cache都会失效，而OS管理的PageCache依然可以继续使用。PageCache还只是第一步，Kafka为了进一步的优化性能还采用了Sendfile技术。在解释Sendfile之前，首先介绍一下传统的网络I/O操作流程，大体上分为以下4步：\n\n 1. OS 从硬盘把数据读到内核区的PageCache\n 2. 用户进程把数据从内核区Copy到用户区\n 3. 然后用户进程再把数据写入到Socket，数据流入内核区的Socket Buffer上\n 4. OS 再把数据从Buffer中Copy到网卡的Buffer上，这样完成一次发送\n\n\n![](/images/1021389888-56442ffade963.jpg)\n\n整个过程共经历两次Context Switch，四次System Call。同一份数据在内核Buffer与用户Buffer之间重复拷贝，效率低下。其中2、3两步没有必要，完全可以直接在内核区完成数据拷贝。这也正是Sendfile所解决的问题，经过Sendfile优化后，整个I/O过程就变成了下面这个样子。 \n\n![](/images/4284736387-56443027674a2.jpg)\n\n通过以上的介绍不难看出，Kafka的设计初衷是尽一切努力在内存中完成数据交换，无论是对外作为一整个消息系统，或是内部同底层操作系统的交互。如果Producer和Consumer之间生产和消费进度上配合得当，完全可以实现数据交换零I/O。这也就是我为什么说Kafka使用“硬盘”并没有带来过多性能损失的原因。下面是在生产环境中采到的一些指标。\n(20 Brokers, 75 Partitions per Broker, 110k msg/s) \n\n![](/images/1593922197-5644305578f81.jpg)\n\n此时的集群只有写，没有读操作。10M/s左右的Send的流量是Partition之间进行Replicate而产生的。从recv和writ的速率比较可以看出，写盘是使用Asynchronous+Batch的方式，底层OS可能还会进行磁盘写顺序优化。而在有Read Request进来的时候分为两种情况，第一种是内存中完成数据交换。\n\n \n![](/images/1537103758-564430720edc9.jpg)\n\nSend流量从平均10M/s增加到了到平均60M/s，而磁盘Read只有不超过50KB/s。PageCache降低磁盘I/O效果非常明显。接下来是读一些收到了一段时间，已经从内存中被换出刷写到磁盘上的老数据。 \n\n![](/images/1836079238-56443081660f3.jpg)\n\n其他指标还是老样子，而磁盘Read已经飚高到40+MB/s。此时全部的数据都已经是走硬盘了(对硬盘的顺序读取OS层会进行Prefill PageCache的优化)。依然没有任何性能问题。\n   \n__Tips__：\n\n 1. Kafka官方并不建议通过Broker端的log.flush.interval.messages和log.flush.interval.ms来强制写盘，认为数据的可靠性应该通过Replica来保证，而强制Flush数据到磁盘会对整体性能产生影响\n 2. 可以通过调整/proc/sys/vm/dirty_background_ratio和/proc/sys/vm/dirty_ratio来调优性能\n 3. 脏页率超过第一个指标会启动pdflush开始Flush Dirty PageCache\n 4. 脏页率超过第二个指标会阻塞所有的写操作来进行Flush\n 5. 根据不同的业务需求可以适当的降低dirty_background_ratio和提高dirty_ratio\n\n# Partition\nPartition是Kafka可以很好的横向扩展和提供高并发处理以及实现Replication的基础。\n  \n扩展性方面。首先，Kafka允许Partition在集群内的Broker之间任意移动，以此来均衡可能存在的数据倾斜问题。其次，Partition支持自定义的分区算法，例如可以将同一个Key的所有消息都路由到同一个Partition上去。 同时Leader也可以在In-Sync的Replica中迁移。由于针对某一个Partition的所有读写请求都是只由Leader来处理，所以Kafka会尽量把Leader均匀的分散到集群的各个节点上，以免造成网络流量过于集中。\n  \n并发方面。任意Partition在某一个时刻只能被一个Consumer Group内的一个Consumer消费(反过来一个Consumer则可以同时消费多个Partition)，Kafka非常简洁的Offset机制最小化了Broker和Consumer之间的交互，这使Kafka并不会像同类其他消息队列一样，随着下游Consumer数目的增加而成比例的降低性能。此外，如果多个Consumer恰巧都是消费时间序上很相近的数据，可以达到很高的PageCache命中率，因而Kafka可以非常高效的支持高并发读操作，实践中基本可以达到单机网卡上限。\n   \n不过，Partition的数量并不是越多越好，Partition的数量越多，平均到每一个Broker上的数量也就越多。考虑到Broker宕机(Network Failure, Full GC)的情况下，需要由Controller来为所有宕机的Broker上的所有Partition重新选举Leader，假设每个Partition的选举消耗10ms，如果Broker上有500个Partition，那么在进行选举的5s的时间里，对上述Partition的读写操作都会触发LeaderNotAvailableException。  \n再进一步，如果挂掉的Broker是整个集群的Controller，那么首先要进行的是重新任命一个Broker作为Controller。新任命的Controller要从Zookeeper上获取所有Partition的Meta信息，获取每个信息大概3-5ms，那么如果有10000个Partition这个时间就会达到30s-50s。而且不要忘记这只是重新启动一个Controller花费的时间，在这基础上还要再加上前面说的选举Leader的时间 -_-!!!!!!  \n此外，在Broker端，对Producer和Consumer都使用了Buffer机制。其中Buffer的大小是统一配置的，数量则与Partition个数相同。如果Partition个数过多，会导致Producer和Consumer的Buffer内存占用过大。  \n__Tips__：\n\n 1. Partition的数量尽量提前预分配，虽然可以在后期动态增加Partition，但是会冒着可能破坏Message Key和Partition之间对应关系的风险\n 2. Replica的数量不要过多，如果条件允许尽量把Replica集合内的Partition分别调整到不同的Rack\n 3. 尽一切努力保证每次停Broker时都可以Clean Shutdown，否则问题就不仅仅是恢复服务所需时间长，还可能出现数据损坏或其他很诡异的问题\n\n# Producer\n\nKafka的研发团队表示在0.8版本里用Java重写了整个Producer，据说性能有了很大提升。我还没有亲自对比试用过，这里就不做数据对比了。本文结尾的扩展阅读里提到了一套我认为比较好的对照组，有兴趣的同学可以尝试一下。  \n其实在Producer端的优化大部分消息系统采取的方式都比较单一，无非也就化零为整、同步变异步这么几种。  \nKafka系统默认支持MessageSet，把多条Message自动地打成一个Group后发送出去，均摊后拉低了每次通信的RTT。而且在组织MessageSet的同时，还可以把数据重新排序，从爆发流式的随机写入优化成较为平稳的线性写入。  \n此外，还要着重介绍的一点是，Producer支持End-to-End的压缩。数据在本地压缩后放到网络上传输，在Broker一般不解压(除非指定要Deep-Iteration)，直至消息被Consume之后在客户端解压。  \n当然用户也可以选择自己在应用层上做压缩和解压的工作(毕竟Kafka目前支持的压缩算法有限，只有GZIP和Snappy)，不过这样做反而会意外的降低效率！！！！ Kafka的End-to-End压缩与MessageSet配合在一起工作效果最佳，上面的做法直接割裂了两者间联系。至于道理其实很简单，压缩算法中一条基本的原理“重复的数据量越多，压缩比越高”。无关于消息体的内容，无关于消息体的数量，大多数情况下输入数据量大一些会取得更好的压缩比。   \n不过Kafka采用MessageSet也导致在可用性上一定程度的妥协。每次发送数据时，Producer都是send()之后就认为已经发送出去了，但其实大多数情况下消息还在内存的MessageSet当中，尚未发送到网络，这时候如果Producer挂掉，那就会出现丢数据的情况。  \n为了解决这个问题，Kafka在0.8版本的设计借鉴了网络当中的ack机制。如果对性能要求较高，又能在一定程度上允许Message的丢失，那就可以设置request.required.acks=0 来关闭ack，以全速发送。如果需要对发送的消息进行确认，就需要设置request.required.acks为1或-1，那么1和-1又有什么区别呢？这里又要提到前面聊的有关Replica数量问题。如果配置为1，表示消息只需要被Leader接收并确认即可，其他的Replica可以进行异步拉取无需立即进行确认，在保证可靠性的同时又不会把效率拉得很低。如果设置为-1，表示消息要Commit到该Partition的ISR集合中的所有Replica后，才可以返回ack，消息的发送会更安全，而整个过程的延迟会随着Replica的数量正比增长，这里就需要根据不同的需求做相应的优化。   \n__Tips__：\n1. Producer的线程不要配置过多，尤其是在Mirror或者Migration中使用的时候，会加剧目标集群Partition消息乱序的情况(如果你的应用场景对消息顺序很敏感的话)\n2. 0.8版本的request.required.acks默认是0(同0.7)\n\n# Consumer\nConsumer端的设计大体上还算是比较常规的。\n\n- 通过Consumer Group，可以支持生产者消费者和队列访问两种模式\n- Consumer API分为High level和Low level两种。前一种重度依赖Zookeeper，所以性能差一些且不自由，但是超省心。第二种不依赖Zookeeper服务，无论从自由度和性能上都有更好的表现，但是所有的异常(Leader迁移、Offset越界、Broker宕机等)和Offset的维护都需要自行处理\n- 大家可以关注下不日发布的0.9 Release。开发人员又用Java重写了一套Consumer。把两套API合并在一起，同时去掉了对Zookeeper的依赖。据说性能有大幅度提升\n\n__Tips__：\n\n强烈推荐使用Low level API，虽然繁琐一些，但是目前只有这个API可以对Error数据进行自定义处理，尤其是处理Broker异常或由于Unclean Shutdown导致的Corrupted Data时，否则无法Skip只能等着“坏消息”在Broker上被Rotate掉，在此期间该Replica将会一直处于不可用状态。\n\n# 参考\n 1. https://segmentfault.com/a/1190000003985468\n \n \n","tags":["消息队列"]},{"title":"Hello World","url":"/2018/06/11/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","tags":["说明"]}]